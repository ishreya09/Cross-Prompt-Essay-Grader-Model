{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/ishreya09/ProTACT","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-01T05:56:41.056601Z","iopub.execute_input":"2024-11-01T05:56:41.057033Z","iopub.status.idle":"2024-11-01T05:56:42.227439Z","shell.execute_reply.started":"2024-11-01T05:56:41.056992Z","shell.execute_reply":"2024-11-01T05:56:42.226130Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"fatal: destination path 'ProTACT' already exists and is not an empty directory.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2024-11-01T06:04:26.738405Z","iopub.execute_input":"2024-11-01T06:04:26.738876Z","iopub.status.idle":"2024-11-01T06:04:41.397846Z","shell.execute_reply.started":"2024-11-01T06:04:26.738833Z","shell.execute_reply":"2024-11-01T06:04:41.396327Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.15.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.4)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.8.30)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\nInstalling collected packages: gdown\nSuccessfully installed gdown-5.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!cp -r /kaggle/working/ProTACT/* /kaggle/working/\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T05:56:42.230168Z","iopub.execute_input":"2024-11-01T05:56:42.230591Z","iopub.status.idle":"2024-11-01T05:56:44.130680Z","shell.execute_reply.started":"2024-11-01T05:56:42.230517Z","shell.execute_reply":"2024-11-01T05:56:44.129283Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"import gdown\nimport os\n\n# Create directory if it doesn't exist\nos.makedirs('embeddings', exist_ok=True)\n\n# https://drive.google.com/file/d/1qUImUtKmpspJCxAQY2OYD5DFlvvZA4IZ/view?usp=sharing\n\n# Google Drive file ID\nfile_id = \"1qUImUtKmpspJCxAQY2OYD5DFlvvZA4IZ\"\n\n# Download file to the specified directory\ngdown.download(f\"https://drive.google.com/uc?id={file_id}\", 'embeddings/glove.6B.50d.txt', quiet=False)","metadata":{"execution":{"iopub.status.busy":"2024-11-01T06:04:45.023731Z","iopub.execute_input":"2024-11-01T06:04:45.024236Z","iopub.status.idle":"2024-11-01T06:04:55.765697Z","shell.execute_reply.started":"2024-11-01T06:04:45.024188Z","shell.execute_reply":"2024-11-01T06:04:55.764354Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1qUImUtKmpspJCxAQY2OYD5DFlvvZA4IZ\nFrom (redirected): https://drive.google.com/uc?id=1qUImUtKmpspJCxAQY2OYD5DFlvvZA4IZ&confirm=t&uuid=65c7f381-ab6d-423a-9428-90037e5dcdb2\nTo: /kaggle/working/embeddings/glove.6B.50d.txt\n100%|██████████| 171M/171M [00:05<00:00, 30.8MB/s] \n","output_type":"stream"},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"'embeddings/glove.6B.50d.txt'"},"metadata":{}}]},{"cell_type":"code","source":"import os\nimport time\nimport argparse\nimport random\nimport numpy as np\nfrom models.ProTACT import build_ProTACT\nimport tensorflow as tf\nfrom configs.configs import Configs\nfrom utils.read_data_pr import read_pos_vocab, read_word_vocab, read_prompts_we, read_essays_prompts, read_prompts_pos\nfrom utils.general_utils import get_scaled_down_scores, pad_hierarchical_text_sequences, get_attribute_masks, load_word_embedding_dict, build_embedd_table\nfrom evaluators.multitask_evaluator_all_attributes import Evaluator as AllAttEvaluator\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\n\nclass CustomHistory(keras.callbacks.Callback):\n    def init(self):\n        self.train_loss = []\n        self.val_loss = []\n        self.train_acc = []\n        self.val_acc = []        \n        \n    def on_epoch_end(self, batch, logs={}):\n        self.train_loss.append(logs.get('loss'))\n        self.val_loss.append(logs.get('val_loss'))\n        self.train_acc.append(logs.get('acc'))\n        self.val_acc.append(logs.get('val_acc'))\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T05:56:44.132448Z","iopub.execute_input":"2024-11-01T05:56:44.132849Z","iopub.status.idle":"2024-11-01T05:56:44.144804Z","shell.execute_reply.started":"2024-11-01T05:56:44.132805Z","shell.execute_reply":"2024-11-01T05:56:44.143650Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"test_prompt_id = 1\nseed = 12\nnum_heads = 2\nfeatures_path = \"/kaggle/working/data/LDA/hand_crafted_final_1.csv\"\n\nnp.random.seed(seed)\ntf.random.set_seed(seed)\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\n\nprint(\"Test prompt id is {} of type {}\".format(test_prompt_id, type(test_prompt_id)))\nprint(\"Seed: {}\".format(seed))\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T05:56:44.147756Z","iopub.execute_input":"2024-11-01T05:56:44.148264Z","iopub.status.idle":"2024-11-01T05:56:44.162059Z","shell.execute_reply.started":"2024-11-01T05:56:44.148222Z","shell.execute_reply":"2024-11-01T05:56:44.160947Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Test prompt id is 1 of type <class 'int'>\nSeed: 12\n","output_type":"stream"}]},{"cell_type":"code","source":"configs = Configs()\n\ndata_path = configs.DATA_PATH\ntrain_path = data_path + str(test_prompt_id) + '/train.pk'\ndev_path = data_path + str(test_prompt_id) + '/dev.pk'\ntest_path = data_path + str(test_prompt_id) + '/test.pk'\npretrained_embedding = configs.PRETRAINED_EMBEDDING\nembedding_path = configs.EMBEDDING_PATH\nreadability_path = configs.READABILITY_PATH\nprompt_path = configs.PROMPT_PATH\nvocab_size = configs.VOCAB_SIZE\nepochs = configs.EPOCHS\nbatch_size = configs.BATCH_SIZE\nprint(\"Numhead : \", num_heads, \" | Features : \", features_path, \" | Pos_emb : \", configs.EMBEDDING_DIM)\n\nread_configs = {\n    'train_path': train_path,\n    'dev_path': dev_path,\n    'test_path': test_path,\n    'features_path': features_path,\n    'readability_path': readability_path,\n    'vocab_size': vocab_size\n}","metadata":{"execution":{"iopub.status.busy":"2024-11-01T05:56:44.163438Z","iopub.execute_input":"2024-11-01T05:56:44.163875Z","iopub.status.idle":"2024-11-01T05:56:44.179378Z","shell.execute_reply.started":"2024-11-01T05:56:44.163836Z","shell.execute_reply":"2024-11-01T05:56:44.178191Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Numhead :  2  | Features :  /kaggle/working/data/LDA/hand_crafted_final_1.csv  | Pos_emb :  50\n","output_type":"stream"}]},{"cell_type":"code","source":"# contains all the paths in a dict\nread_configs","metadata":{"execution":{"iopub.status.busy":"2024-11-01T05:56:44.180898Z","iopub.execute_input":"2024-11-01T05:56:44.181267Z","iopub.status.idle":"2024-11-01T05:56:44.199737Z","shell.execute_reply.started":"2024-11-01T05:56:44.181226Z","shell.execute_reply":"2024-11-01T05:56:44.198441Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"{'train_path': 'data/cross_prompt_attributes/1/train.pk',\n 'dev_path': 'data/cross_prompt_attributes/1/dev.pk',\n 'test_path': 'data/cross_prompt_attributes/1/test.pk',\n 'features_path': '/kaggle/working/data/LDA/hand_crafted_final_1.csv',\n 'readability_path': 'data/allreadability.pickle',\n 'vocab_size': 4000}"},"metadata":{}}]},{"cell_type":"markdown","source":"Sure, let me clarify with an example.\n\nIn `prompt_pos_data`, `max_sentnum` and `max_sentlen` define limits on the structure of prompts by standardizing the number of sentences and words in each sentence across all prompts.\n\n### 1. `max_sentnum`: 8\n\n- This means that each prompt has been limited to a maximum of **8 sentences**. \n- If a prompt has **fewer than 8 sentences**, extra sentences will be added (usually with padding) to reach 8 sentences.\n- If a prompt has **more than 8 sentences**, it will be truncated to only include the first 8 sentences.\n- This standardization ensures that the model always sees prompts with 8 sentences, making it easier to handle prompts consistently.\n\n### 2. `max_sentlen`: 18\n\n- This means that each sentence has been limited to a maximum of **18 words** (or POS tags, in this case).\n- If a sentence has **fewer than 18 words**, it will be padded to reach 18 words.\n- If a sentence has **more than 18 words**, it will be truncated to keep only the first 18 words.\n  \n### Example\n\nLet’s say we have a prompt with 3 sentences:\n\n1. Sentence 1: `['NNS', 'VB', 'NN', 'JJ']` (4 words)\n2. Sentence 2: `['NN', 'DT', 'VB', 'NNS', 'IN', 'NN', 'VBZ']` (7 words)\n3. Sentence 3: `['DT', 'JJ', 'NN']` (3 words)\n\nWithout standardization, we would represent this prompt as:\n```\n[\n    [3, 18, 5, 7],            # Sentence 1\n    [5, 2, 18, 3, 4, 5, 10],  # Sentence 2\n    [2, 7, 5]                 # Sentence 3\n]\n```\n\nAfter applying `max_sentnum=8` and `max_sentlen=18`, the prompt will be transformed into a consistent shape, such as:\n\n```\n[\n    [3, 18, 5, 7, 0, 0, 0, ..., 0],  # Sentence 1 padded to 18 words\n    [5, 2, 18, 3, 4, 5, 10, 0, ..., 0],  # Sentence 2 padded to 18 words\n    [2, 7, 5, 0, ..., 0],          # Sentence 3 padded to 18 words\n    [0, 0, 0, ..., 0],             # Padding for 8 sentences\n    [0, 0, 0, ..., 0],\n    [0, 0, 0, ..., 0],\n    [0, 0, 0, ..., 0],\n    [0, 0, 0, ..., 0]\n]\n```\n\nNow each prompt is represented as an 8x18 matrix, where each cell is a POS tag ID, making the input shape uniform for all prompts in the dataset. This uniform structure is crucial for batching data efficiently during training.","metadata":{}},{"cell_type":"code","source":"# read POS for prompts\n\"\"\"\nThis dictionary pos_vocab maps part-of-speech (POS) tags to integer IDs. The POS tags represent parts of speech such as determiners, nouns, verbs, and adjectives. Here’s a closer look:\n\n'<pad>': 0, '<unk>': 1 — Special tokens for padding and unknown words.\nThe integer mappings for tags like 'DT': 2, 'NNS': 3, etc., are used to represent words by their grammatical roles in the prompt data.\nFor example:\n\nNN: Noun (e.g., 5)\nVBD: Verb, past tense (e.g., 6)\nJJ: Adjective (e.g., 7)\nThese mappings allow the model to work with POS tags as numeric data during processing.\n\nThe prompt_pos_data dictionary contains the POS-encoded prompt data and metadata:\n\nprompt_pos: This is a list of prompts, where each prompt is encoded as a list of sentences, and each sentence is represented as a list of integers corresponding to POS tags.\n\nExample: [[3, 20, 3, 5, 10, 3, 5, 8], ...]\nIn this sentence, the integers represent a sequence of POS tags for words in that sentence. For instance, [3, 20, 3, 5, 10, 3, 5, 8] would correspond to the POS tags like NNS, VBP, etc., in the sequence.\nEach prompt has multiple sentences, with each sentence containing POS-encoded words.\n\nprompt_ids: List of IDs for each prompt. Each integer in this list corresponds to a prompt, allowing for easy reference during training and evaluation.\n\nmax_sentnum: 8 — The maximum number of sentences in a prompt. This ensures all prompts have a consistent number of sentences, either through truncation or padding.\n\nmax_sentlen: 18 — The maximum length of a sentence across all prompts. Each sentence will be either padded or truncated to 18 tokens.\n\n\n\n\n\"\"\"\npos_vocab = read_pos_vocab(read_configs)\nprompt_pos_data = read_prompts_pos(prompt_path, pos_vocab) # for prompt POS embedding\n\nprint(pos_vocab)\nprint(prompt_pos_data)","metadata":{"execution":{"iopub.status.busy":"2024-11-01T05:56:44.201133Z","iopub.execute_input":"2024-11-01T05:56:44.201604Z","iopub.status.idle":"2024-11-01T05:56:44.613053Z","shell.execute_reply.started":"2024-11-01T05:56:44.201550Z","shell.execute_reply":"2024-11-01T05:56:44.612034Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":" prompt_pos size: 8\n{'<pad>': 0, '<unk>': 1, 'DT': 2, 'NNS': 3, 'IN': 4, 'NN': 5, 'VBD': 6, 'JJ': 7, '.': 8, 'CD': 9, 'VBZ': 10, 'RB': 11, 'VBG': 12, 'TO': 13, 'PRP$': 14, 'PRP': 15, 'VBN': 16, 'WDT': 17, 'VB': 18, 'WRB': 19, 'VBP': 20, 'MD': 21, 'CC': 22, 'EX': 23, ',': 24, 'JJR': 25, 'RP': 26, 'WP': 27, ':': 28, 'NNP': 29, 'RBR': 30, 'FW': 31, 'POS': 32, 'JJS': 33, \"''\": 34}\n{'prompt_pos': [[[3, 20, 3, 5, 10, 3, 5, 8], [5, 3, 5, 20, 3, 7, 5, 3, 8], [5, 5, 5, 5, 7, 3, 5, 20, 11, 3, 3, 11, 20, 3, 20, 7, 3, 8], [3, 7, 3, 8], [3, 7, 3, 12, 7, 5, 3, 30, 5, 12, 12, 5, 12, 5, 3, 8], [7, 5, 7, 5, 5, 5, 3, 3, 3, 8], [5, 3, 20, 8]], [[5, 3, 8], [15, 20, 5, 20, 5, 3, 3, 16, 5, 8], [11, 18, 5, 5, 5, 5, 11, 11, 11, 5, 11, 8], [3, 6, 5, 15, 8], [5, 5, 5, 8], [11, 7, 20, 5, 12, 3, 7, 3, 8], [18, 7, 3, 3, 5, 3, 3, 11, 8], [16, 3, 6, 7, 5, 5, 12, 3, 5, 3, 5, 8]], [[7, 5, 10, 3, 12, 7, 5, 8], [5, 20, 3, 20, 5, 5, 8]], [[16, 7, 7, 5, 8], [18, 11, 5, 6, 11, 12, 3, 6, 7, 5, 5, 12, 18, 5, 8], [7, 5, 10, 7, 3, 5, 5, 8], [5, 20, 3, 3, 5, 5, 3, 8]], [[5, 5, 6, 5, 5, 8], [5, 5, 5, 7, 5, 5, 8]], [[16, 7, 7, 3, 3, 20, 5, 5, 6, 12, 7, 3, 5, 8], [5, 5, 5, 7, 5, 5, 8]], [[7, 5, 8], [5, 10, 7, 5, 8], [7, 5, 5, 3, 4, 12, 8], [9, 12, 7, 5, 5, 7, 7, 5, 5, 5, 20, 7, 7, 5, 5, 5, 8]], [[7, 3, 5, 8], [5, 5, 6, 30, 33, 5, 9, 3, 8], [7, 3, 20, 5, 7, 5, 5, 8], [18, 7, 5, 5, 9, 5, 5, 8]]], 'prompt_ids': [1, 2, 3, 4, 5, 6, 7, 8], 'max_sentnum': 8, 'max_sentlen': 18}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Here's a breakdown of your code's components and the output variables.\n\n### Explanation of Code and Output\n\n1. **Vocabulary (`word_vocab`):**\n   - The `word_vocab` dictionary maps words (like `'the'`, `'to'`, and special tokens like `<pad>`, `<unk>`, `<num>`) to unique IDs.\n   - This is used to convert each word in the prompts to its corresponding ID for model processing.\n\n2. **Prompt Data (`prompt_data`):**\n   - `prompt_words`: Contains the tokenized prompts in word-ID format (lists of integers). Each word has been converted to its ID from `word_vocab`. Sentences are limited to a maximum of 8 (`max_sentnum`) and 18 tokens per sentence (`max_sentlen`), as specified.\n   - `prompt_ids`: This is a list of IDs for each prompt, where each number represents a unique prompt.\n\n3. **Example Breakdown:**\n   - `prompt_words`: An example list of tokenized prompts.\n     ```python\n     'prompt_words': [\n         [\n             [37, 272, 2141, 160, 3829, 2873, 621, 4],  # First sentence of the first prompt\n             [1023, 1, 2232, 201, 2141, 837, 724, 37, 4],  # Second sentence of the first prompt\n             ...\n         ],\n         [\n             [218, 125, 4],  # First sentence of the second prompt\n             ...\n         ],\n         ...\n     ]\n     ```\n   - This list has each prompt represented as an 8x18 matrix, where sentences shorter than 18 tokens are padded, and prompts with fewer than 8 sentences are padded with empty sentences.\n\n4. **Prompt Word Sizes (`max_sentnum` and `max_sentlen`):**\n   - The `max_sentnum: 8` and `max_sentlen: 18` settings specify that each prompt should contain 8 sentences with a maximum of 18 tokens each.\n   - Shorter sentences or prompts are padded to match this size, ensuring all data is of consistent shape, which is critical for efficient model training.\n","metadata":{}},{"cell_type":"code","source":"    \n# read words for prompts \nword_vocab = read_word_vocab(read_configs)\nprompt_data = read_prompts_we(prompt_path, word_vocab) # for prompt word embedding \n\nprint(word_vocab)\nprint(prompt_data)","metadata":{"execution":{"iopub.status.busy":"2024-11-01T05:56:44.614739Z","iopub.execute_input":"2024-11-01T05:56:44.615128Z","iopub.status.idle":"2024-11-01T05:57:50.958304Z","shell.execute_reply.started":"2024-11-01T05:56:44.615089Z","shell.execute_reply":"2024-11-01T05:57:50.957037Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":" prompt_words size: 8\n{'<pad>': 0, '<unk>': 1, '<num>': 2, 'the': 3, '.': 4, 'to': 5, ',': 6, 'and': 7, 'a': 8, 'of': 9, 'i': 10, 'that': 11, 'in': 12, 'it': 13, 'was': 14, 'is': 15, '@caps': 16, 'be': 17, 'for': 18, 'they': 19, 'we': 20, 'my': 21, 'he': 22, 'you': 23, 'not': 24, 'have': 25, 'this': 26, 'on': 27, 'with': 28, 'would': 29, 'are': 30, 'there': 31, 'or': 32, 'because': 33, 'so': 34, 'when': 35, 'she': 36, 'people': 37, 'if': 38, 'but': 39, 'had': 40, 'all': 41, 'at': 42, 'about': 43, 'as': 44, 'do': 45, \"n't\": 46, 'were': 47, 'her': 48, 'his': 49, 'what': 50, 'one': 51, 'should': 52, 'like': 53, 'books': 54, 'from': 55, 'building': 56, 'me': 57, 'just': 58, 'their': 59, 'out': 60, 'can': 61, 'could': 62, \"'s\": 63, 'by': 64, 'up': 65, 'will': 66, 'them': 67, 'then': 68, 'how': 69, 'get': 70, 'some': 71, 'think': 72, 'book': 73, 'author': 74, '@num': 75, 'time': 76, 'things': 77, '@person': 78, 'also': 79, 'many': 80, 'parents': 81, 'offensive': 82, 'him': 83, 'story': 84, 'our': 85, '?': 86, 'very': 87, 'an': 88, 'go': 89, 'read': 90, 'way': 91, 'mood': 92, 'no': 93, 'even': 94, 'life': 95, 'take': 96, 'more': 97, 'make': 98, 'dirigibles': 99, 'going': 100, 'library': 101, 'other': 102, 'did': 103, 'over': 104, 'family': 105, 'cyclist': 106, 'state': 107, 'back': 108, 'said': 109, 'has': 110, 'home': 111, 'got': 112, 'empire': 113, 'music': 114, 'want': 115, 'something': 116, 'your': 117, 'new': 118, 'these': 119, 'know': 120, 'off': 121, 'us': 122, 'good': 123, 'children': 124, 'libraries': 125, 'mast': 126, 'into': 127, 'see': 128, 'being': 129, 'movies': 130, 'paragraph': 131, 'another': 132, 'patient': 133, 'who': 134, 'day': 135, 'which': 136, 'always': 137, 'made': 138, 'really': 139, 'down': 140, 'around': 141, 'water': 142, 'right': 143, 'person': 144, '!': 145, 'why': 146, 'first': 147, 'test': 148, 'builders': 149, 'saeng': 150, 'memoir': 151, 'any': 152, 'where': 153, 'only': 154, 'went': 155, 'been': 156, 'most': 157, 'laughter': 158, \"'\": 159, 'everyone': 160, 'someone': 161, '@location': 162, 'find': 163, 'thing': 164, 'setting': 165, 'mooring': 166, 'never': 167, 'love': 168, 'happy': 169, 'much': 170, 'after': 171, 'dirigible': 172, 'say': 173, 'friends': 174, 'different': 175, '@month': 176, '@organization': 177, 'obstacles': 178, 'bad': 179, 'faced': 180, 'laugh': 181, 'again': 182, 'through': 183, 'kids': 184, 'now': 185, '�': 186, 'too': 187, 'still': 188, 'dock': 189, 'come': 190, 'its': 191, 'magazines': 192, 'house': 193, 'feel': 194, 'says': 195, 'narciso': 196, 'does': 197, 'mom': 198, 'little': 199, 'came': 200, 'believe': 201, 'those': 202, 'top': 203, 'world': 204, 'need': 205, 'away': 206, 'such': 207, 'than': 208, ')': 209, 'hibiscus': 210, 'certain': 211, 'put': 212, 'example': 213, 'shelves': 214, '(': 215, 'laughing': 216, 'place': 217, 'censorship': 218, 'reason': 219, 'better': 220, 'lot': 221, 'able': 222, 'every': 223, 'same': 224, 'shows': 225, 'hard': 226, 'school': 227, 'started': 228, 'reading': 229, 'while': 230, '@date': 231, 'well': 232, 'great': 233, 'obstacle': 234, 'told': 235, 'ever': 236, 'might': 237, 'thought': 238, 'two': 239, 'material': 240, 'look': 241, 'child': 242, 'found': 243, 'everything': 244, 'created': 245, 'help': 246, 'next': 247, 'patience': 248, 'long': 249, 'allow': 250, 'movie': 251, 'wanted': 252, 'before': 253, 'old': 254, 'keep': 255, 'materials': 256, 'hydrogen': 257, 'problem': 258, 'used': 259, 'finally': 260, 'left': 261, 'shelf': 262, 'end': 263, 'let': 264, 'wait': 265, 'grateful': 266, 'though': 267, 'trying': 268, 'having': 269, 'give': 270, 'last': 271, 'use': 272, 'best': 273, 'show': 274, 'work': 275, 'each': 276, 'law': 277, 'anything': 278, 'tell': 279, 'together': 280, 'features': 281, 'took': 282, 'own': 283, 'makes': 284, 'air': 285, 'getting': 286, 'rodriguez': 287, 'taken': 288, 'removed': 289, 'am': 290, 'watch': 291, 'others': 292, 'try': 293, 'idea': 294, 'nothing': 295, 'age': 296, 'dad': 297, ';': 298, 'times': 299, 'area': 300, 'winds': 301, 'road': 302, 'states': 303, 'else': 304, 'friend': 305, 'saying': 306, 'start': 307, 'concludes': 308, 'spring': 309, 'important': 310, 'big': 311, 'learn': 312, 'making': 313, 'without': 314, 'fun': 315, 'taking': 316, 'once': 317, 'waiting': 318, 'affect': 319, 'ride': 320, 'hot': 321, 'until': 322, 'mean': 323, 'kind': 324, 'dont': 325, 'enough': 326, 'few': 327, 'wrong': 328, 'mother': 329, 'high': 330, 'low': 331, 'listen': 332, 'done': 333, '...': 334, 'both': 335, 'line': 336, 'young': 337, 'due': 338, 'whole': 339, 'hope': 340, 'geese': 341, 'nature': 342, 'cause': 343, 'here': 344, 'problems': 345, 'room': 346, 'almost': 347, 'wind': 348, 'face': 349, 'affected': 350, ':': 351, 'part': 352, 'doing': 353, 'attempting': 354, 'york': 355, 'stuff': 356, 'frame': 357, 'knew': 358, 'country': 359, 'public': 360, 'stop': 361, 'point': 362, 'stress': 363, 'words': 364, 'felt': 365, 'today': 366, 'asked': 367, 'areas': 368, 'funny': 369, 'plant': 370, 'open': 371, 'since': 372, 'matter': 373, 'against': 374, 'talking': 375, 'brother': 376, 'talk': 377, 'car': 378, 'violent': 379, 'lives': 380, 'saw': 381, 'urban': 382, 'year': 383, 'opinion': 384, 'looking': 385, 'kept': 386, 'sometimes': 387, 'close': 388, 'safety': 389, 'change': 390, 'ways': 391, 'cuban': 392, 'hours': 393, 'comes': 394, 'highly': 395, 'outside': 396, 'looked': 397, \"'m\": 398, 'stay': 399, 'airships': 400, 'didn�t': 401, 'flammable': 402, 'sure': 403, 'feeling': 404, 'means': 405, 'sister': 406, 'flying': 407, 'minutes': 408, 'remove': 409, 'currents': 410, 'reader': 411, 'girl': 412, 'conclusion': 413, 'called': 414, 'past': 415, 'fact': 416, 'censored': 417, 'section': 418, 'anyone': 419, 'thats': 420, 'wants': 421, 'years': 422, 'gave': 423, 'maybe': 424, 'needed': 425, 'happen': 426, 'live': 427, 'etc': 428, 'magazine': 429, 'turned': 430, 'ca': 431, 'waited': 432, 'realized': 433, 'happened': 434, 'hear': 435, 'hills': 436, 'myself': 437, 'understand': 438, 'later': 439, 'however': 440, 'town': 441, 'reasons': 442, 'simple': 443, 'hour': 444, 'excerpt': 445, 'become': 446, 'mind': 447, 'days': 448, 'speed': 449, 'second': 450, 'desert': 451, 'constantly': 452, 'heat': 453, 'city': 454, 'seen': 455, 'strong': 456, 'kid': 457, 'above': 458, 'safe': 459, 'ready': 460, 'forget': 461, 'information': 462, 'winter': 463, 'learned': 464, 'alot': 465, 'remember': 466, 'buildings': 467, 'decided': 468, 'memories': 469, 'herself': 470, 'happiness': 471, 'budding': 472, 'offended': 473, 'parent': 474, 'warm': 475, 'door': 476, 'rather': 477, 'game': 478, 'three': 479, 'language': 480, 'enjoy': 481, 'filled': 482, 'return': 483, 'adult': 484, 'relationship': 485, 'helium': 486, 'man': 487, 'loved': 488, 'laughed': 489, 'pick': 490, 'talks': 491, 'play': 492, 'during': 493, 'leave': 494, 'turn': 495, 'united': 496, 'sat': 497, 'shifting': 498, 'sad': 499, 'adults': 500, 'sense': 501, 'fire': 502, 'loving': 503, 'flower': 504, 'main': 505, 'freedom': 506, 'situation': 507, 'soon': 508, 'along': 509, 'pass': 510, 'set': 511, '@time': 512, 'instead': 513, 'check': 514, 'architects': 515, 'ship': 516, 'front': 517, 'class': 518, 'itself': 519, 'type': 520, 'goes': 521, 'probably': 522, \"'ve\": 523, 'allowed': 524, 'although': 525, 'failed': 526, 'ask': 527, 'coming': 528, 'already': 529, 'behind': 530, 'populated': 531, 'feet': 532, 'real': 533, 'walked': 534, 'care': 535, '&': 536, 'mad': 537, 'quote': 538, 'eyes': 539, 'food': 540, 'add': 541, 'tried': 542, 'yet': 543, 'pretty': 544, 'head': 545, 'store': 546, 'simply': 547, 'between': 548, \"'re\": 549, 'content': 550, 'heard': 551, 'lead': 552, 'walk': 553, 'land': 554, 'feels': 555, 'censor': 556, 'watching': 557, 'ran': 558, 'lack': 559, 'older': 560, 'throughout': 561, 'began': 562, 'exceed': 563, 'true': 564, 'gets': 565, 'inside': 566, 'across': 567, 'sacrifice': 568, 'choice': 569, 'must': 570, 'growing': 571, 'yes': 572, 'nice': 573, 'side': 574, 'future': 575, 'word': 576, 'thinking': 577, 'short': 578, 'group': 579, 'greatest': 580, 'move': 581, 'culture': 582, 'gives': 583, 'neighborhood': 584, 'posted': 585, 'dangerous': 586, 'smile': 587, 'money': 588, 'often': 589, 'illegal': 590, 'bike': 591, 'docking': 592, 'terrain': 593, 'agree': 594, 'night': 595, 'seeing': 596, 'takes': 597, 'sit': 598, 'needs': 599, 'hand': 600, 'creates': 601, 'small': 602, 'trip': 603, 'worse': 604, 'seemed': 605, 'order': 606, 'lost': 607, 'actually': 608, 'either': 609, 'don�t': 610, 'moved': 611, 'thousand': 612, 'landing': 613, 'hurt': 614, 'limit': 615, 'bring': 616, 'became': 617, 'friendship': 618, 'rough': 619, 'walking': 620, 'society': 621, 'meant': 622, 'ended': 623, 'inappropriate': 624, 'snow': 625, 'difficult': 626, 'riding': 627, 'song': 628, 'childhood': 629, 'seem': 630, 'telling': 631, 'ones': 632, 'kitchen': 633, 'weather': 634, 'ahead': 635, 'beginning': 636, 'cooking': 637, 'tired': 638, 'history': 639, 'california': 640, 'themselves': 641, 'learning': 642, 'large': 643, 'deal': 644, 'dehydrated': 645, 'worth': 646, 'tells': 647, 'existing': 648, 'whether': 649, 'experience': 650, 'sun': 651, 'whatever': 652, 'name': 653, 'passed': 654, 'flat': 655, 'running': 656, 'brought': 657, 'driving': 658, 'community': 659, 'view': 660, 'media': 661, 'write': 662, 'considered': 663, 'cool': 664, 'types': 665, 'sitting': 666, 'rest': 667, 'therefore': 668, 'half': 669, 'cuba': 670, '�i': 671, 'least': 672, 'choose': 673, 'living': 674, 'huge': 675, 'describes': 676, 'items': 677, 'couple': 678, 'drop': 679, 'self': 680, 'everybody': 681, 'upset': 682, 'affects': 683, 'blimp': 684, 'finds': 685, 'gone': 686, 'buy': 687, 'grow': 688, 'knowing': 689, 'authors': 690, 'younger': 691, 'blood': 692, 'pressure': 693, 'talked': 694, 'phone': 695, 'far': 696, 'pedestrians': 697, 'ideas': 698, 'teacher': 699, 'knowledge': 700, 'single': 701, 'towards': 702, 'full': 703, 'essay': 704, 'appropriate': 705, 'fly': 706, 'accident': 707, 'call': 708, 'upon': 709, 'thankful': 710, 'topic': 711, 'chance': 712, 'boy': 713, 'heart': 714, 'showed': 715, 'middle': 716, 'overcome': 717, 'girls': 718, 'drugs': 719, 'men': 720, 'several': 721, 'blimps': 722, 'tie': 723, 'effect': 724, 'writing': 725, 'swivel': 726, 'harder': 727, 'using': 728, 'hindenburg': 729, 'journey': 730, 'playing': 731, 'moment': 732, 'park': 733, 'extremely': 734, 'fast': 735, 'explains': 736, 'easy': 737, 'bit': 738, 'melt': 739, 'usually': 740, 'hold': 741, 'weights': 742, 'it�s': 743, 'smith': 744, 'banned': 745, 'lastly': 746, 'offend': 747, 'held': 748, 'leaving': 749, 'opinions': 750, 'changed': 751, 'rolling': 752, 'speech': 753, 'issue': 754, 'students': 755, 'based': 756, 'al': 757, 'die': 758, 'censoring': 759, 'run': 760, 'okay': 761, 'job': 762, 'knows': 763, 'sentence': 764, 'favorite': 765, 'completely': 766, 'lived': 767, 'densely': 768, 'longer': 769, 'under': 770, 'helped': 771, 'less': 772, 'listening': 773, 'body': 774, 'dollars': 775, 'especially': 776, 'sex': 777, 'foundation': 778, 'four': 779, 'practical': 780, 'steel': 781, 'excited': 782, 'realize': 783, 'five': 784, 'seems': 785, 'jokes': 786, 'greatful': 787, 'cold': 788, 'purpose': 789, 'express': 790, 'team': 791, 'ground': 792, 'games': 793, 'caused': 794, 'helps': 795, 'trouble': 796, 'energy': 797, 'text': 798, 'meaning': 799, 'thinks': 800, 'father': 801, 'hit': 802, 'starting': 803, 'violence': 804, 'starts': 805, 'giving': 806, 'played': 807, 'course': 808, 'fell': 809, 'stories': 810, 'proud': 811, 'ends': 812, 'given': 813, 'vowed': 814, 'wasn�t': 815, 'allowing': 816, 'directions': 817, 'moored': 818, 'eventually': 819, 'silently': 820, 'grade': 821, 'showing': 822, 'loves': 823, 'readers': 824, 'teach': 825, 'below': 826, 'written': 827, 'immigrants': 828, 'dinner': 829, 'stopped': 830, 'everyday': 831, 'likely': 832, 'working': 833, 'miles': 834, 'moving': 835, 'stated': 836, 'positive': 837, 'sign': 838, 'fine': 839, 'quite': 840, 'overall': 841, 'caring': 842, 'mature': 843, 'article': 844, 'form': 845, 'final': 846, 'major': 847, 'control': 848, 'june': 849, 'free': 850, 'noticed': 851, 'street': 852, 'environment': 853, 'changes': 854, 'cant': 855, 'strength': 856, 'alone': 857, 'sixty': 858, 'hands': 859, 'eat': 860, 'kurmaskie': 861, 'yourself': 862, 'i�m': 863, 'snows': 864, 'question': 865, 'birthday': 866, 'songs': 867, 'roof': 868, 'arms': 869, 'places': 870, 'guy': 871, 'modifications': 872, 'joke': 873, 'rid': 874, 'determination': 875, 'cable': 876, 'personally': 877, 'views': 878, 'na': 879, 'interesting': 880, 'week': 881, 'determined': 882, 'build': 883, 'l�sted': 884, 'sees': 885, 'couldn�t': 886, 'plan': 887, 'closer': 888, 'u': 889, 'easily': 890, 'marcia': 891, 'morning': 892, 'video': 893, 'picture': 894, 'passengers': 895, 'jersey': 896, 'moods': 897, 'create': 898, 'ago': 899, 'early': 900, 'till': 901, 'perfect': 902, 'calm': 903, 'grew': 904, 'yosemite': 905, 'bed': 906, 'amidon': 907, 'hill': 908, 'piece': 909, 'months': 910, 'fair': 911, 'forever': 912, 'that�s': 913, 'subject': 914, 'downtown': 915, \"'d\": 916, 'katherine': 917, 'removing': 918, 'personal': 919, 'flowers': 920, 'drink': 921, 'literature': 922, '�rough': 923, 'entire': 924, 'deserts': 925, 'met': 926, 'table': 927, 'load': 928, 'amount': 929, 'thoughts': 930, 'possible': 931, 'putting': 932, 'thirsty': 933, 'dry': 934, 'rated': 935, 'brings': 936, 'likes': 937, 'paterson': 938, 'fall': 939, 'race': 940, 'character': 941, 'kinds': 942, 'feelings': 943, 'greatly': 944, 'cultures': 945, 'stand': 946, '�when': 947, 'snake': 948, 'exactly': 949, 'lose': 950, 'tether': 951, \"'ll\": 952, 'beautiful': 953, '�winter': 954, 'third': 955, 'within': 956, 'ok': 957, 's': 958, 'case': 959, 'guess': 960, 'worry': 961, 'bus': 962, 'caught': 963, 'himself': 964, 'cousin': 965, 'families': 966, 'gratitude': 967, 'structure': 968, 'im': 969, 'ending': 970, 'anymore': 971, 'late': 972, 'pictures': 973, 'known': 974, 'drive': 975, 'framework': 976, 'concluded': 977, 'arrived': 978, 'project': 979, 'limit�': 980, 'impossible': 981, 'destroyed': 982, 'didnt': 983, 'season': 984, 'answer': 985, 'ten': 986, 'decide': 987, 'reach': 988, 'lunch': 989, 'biggest': 990, 'reality': 991, 'pulled': 992, 'suitable': 993, 'taught': 994, 'shared': 995, 'crying': 996, 'comfortable': 997, 'uses': 998, 'mostly': 999, 'gas': 1000, '�the': 1001, 'handle': 1002, 'crazy': 1003, 'nobody': 1004, 'courage': 1005, 'happens': 1006, 'none': 1007, 'dangling': 1008, 'laws': 1009, 'sight': 1010, 'scared': 1011, 'act': 1012, 'finding': 1013, 'quickly': 1014, 'doctor': 1015, 'vietnam': 1016, 'familiar': 1017, 'fish': 1018, 'juice': 1019, 'homeland': 1020, 'watched': 1021, 'patients': 1022, 'support': 1023, 'attention': 1024, 'liked': 1025, 'wrote': 1026, 'nor': 1027, 'paper': 1028, 'negative': 1029, 'owners': 1030, 'issues': 1031, 'nearly': 1032, 'skills': 1033, 'party': 1034, 'roads': 1035, 'workers': 1036, 'ho': 1037, 'plants': 1038, 'contain': 1039, 'blueprints': 1040, 'hair': 1041, 'confidence': 1042, 'beliefs': 1043, 'amazing': 1044, 'neither': 1045, 'abandoned': 1046, 'successful': 1047, 'wo': 1048, 'lots': 1049, 'quiet': 1050, 'comfort': 1051, 'bought': 1052, 'student': 1053, 'near': 1054, 'joy': 1055, 'tone': 1056, 'begin': 1057, 'added': 1058, 'boring': 1059, 'mouth': 1060, 'schools': 1061, 'modified': 1062, 'german': 1063, 'six': 1064, 'survive': 1065, '�do': 1066, 'definition': 1067, 'voice': 1068, 'foot': 1069, 'guys': 1070, 'complain': 1071, 'shown': 1072, 'looks': 1073, 'weeks': 1074, 'construction': 1075, 'sections': 1076, 'fight': 1077, 'dog': 1078, 'somewhere': 1079, 'gotten': 1080, 'changing': 1081, 'onto': 1082, 'stores': 1083, 'hundred': 1084, 'unsafe': 1085, 'lets': 1086, 'teens': 1087, 'clearly': 1088, 'religion': 1089, 'understanding': 1090, 'ability': 1091, 'share': 1092, 'shelfs': 1093, 'sound': 1094, 'thier': 1095, 'feature': 1096, 'factory': 1097, 'writes': 1098, 'approach': 1099, 'sexual': 1100, 'worked': 1101, 'attempt': 1102, 'pay': 1103, 'wont': 1104, 'break': 1105, 'topics': 1106, 'government': 1107, 'meet': 1108, 'explain': 1109, 'tethered': 1110, 'cut': 1111, 'catch': 1112, 'advice': 1113, 'fit': 1114, 'baby': 1115, 'transmitted': 1116, 'floor': 1117, 'chose': 1118, 'weight': 1119, 'serious': 1120, 'strengthened': 1121, 'letting': 1122, '@money': 1123, 'sleep': 1124, 'special': 1125, 'cry': 1126, 'picked': 1127, 'thank': 1128, 'angry': 1129, 'hang': 1130, 'shop': 1131, 'adapt': 1132, 'statement': 1133, 'stayed': 1134, 'woke': 1135, 'sort': 1136, 'finished': 1137, 'height': 1138, 'teenagers': 1139, 'message': 1140, 'gon': 1141, 'light': 1142, 'human': 1143, 'supply': 1144, 'relative': 1145, 'tears': 1146, 'somebody': 1147, 'hibiscus�': 1148, 'risk': 1149, 'exposed': 1150, 'passionate': 1151, 'passage': 1152, 'distance': 1153, 'level': 1154, 'bathroom': 1155, 'conditions': 1156, 'l': 1157, 'towns': 1158, 'saeng�s': 1159, 'danger': 1160, 'please': 1161, 'described': 1162, 'possibly': 1163, 'standing': 1164, 'dehydration': 1165, 'whats': 1166, 'spent': 1167, 'minds': 1168, 'works': 1169, 'key': 1170, 'offends': 1171, 'reached': 1172, 'named': 1173, 'entertainment': 1174, 'replied': 1175, 'spend': 1176, 'humor': 1177, 'ghost': 1178, 'grandma': 1179, 'specific': 1180, 'truly': 1181, 'experiences': 1182, 'item': 1183, 'racism': 1184, 'black': 1185, 'decision': 1186, 'doesn�t': 1187, 'camp': 1188, 'internet': 1189, 'television': 1190, 'opened': 1191, 'continue': 1192, 'endless': 1193, 'clothes': 1194, 'celebrations': 1195, 'harsh': 1196, 'thanks': 1197, 'slowly': 1198, 'worst': 1199, 'sets': 1200, 'drivers': 1201, 'path': 1202, 'born': 1203, 'failing': 1204, 'wonderful': 1205, 'stood': 1206, 'unless': 1207, 'loud': 1208, 'built': 1209, 'joe': 1210, 'white': 1211, 'horrible': 1212, 'situations': 1213, 'clear': 1214, 'everywhere': 1215, 'ages': 1216, 'shouldnt': 1217, 'becoming': 1218, 'stuck': 1219, 'threw': 1220, 'groups': 1221, 'worried': 1222, 'relationships': 1223, 'office': 1224, 'offense': 1225, 'can�t': 1226, 'hate': 1227, 'wish': 1228, 'ball': 1229, 'wouldn�t': 1230, 'docked': 1231, 'consider': 1232, 'rights': 1233, 'rich': 1234, 'supposed': 1235, 'selflessly': 1236, 'easier': 1237, 'ect': 1238, 'tallest': 1239, 'basically': 1240, 'asking': 1241, 'despite': 1242, 'complaining': 1243, 'bored': 1244, 'stairs': 1245, 'tough': 1246, 'traditional': 1247, 'moor': 1248, 'replaced': 1249, 'hearing': 1250, 'melts': 1251, 'access': 1252, 'ourselves': 1253, 'common': 1254, 'faster': 1255, 'confident': 1256, 'broke': 1257, 'pain': 1258, 'laughs': 1259, 'wouldnt': 1260, 'spot': 1261, 'events': 1262, 'strange': 1263, 'grandparents': 1264, 'stupid': 1265, 'disagree': 1266, 'jobs': 1267, 'computer': 1268, 'number': 1269, 'normal': 1270, 'causing': 1271, 'interested': 1272, 'local': 1273, 'examples': 1274, 'toward': 1275, 'accommodate': 1276, 'conclude': 1277, 'station': 1278, 'sweat': 1279, 'members': 1280, 'instance': 1281, 'happening': 1282, 'fix': 1283, 'step': 1284, 'truth': 1285, 'lesson': 1286, 'rides': 1287, 'checked': 1288, 'imagine': 1289, 'anybody': 1290, 'rap': 1291, 'hanging': 1292, 'culinary': 1293, 'again.�': 1294, 'moments': 1295, 'reminds': 1296, 'grandmother': 1297, 'thousand-foot': 1298, 'clean': 1299, 'ice': 1300, 'asleep': 1301, 'librarian': 1302, 'yelled': 1303, 'hide': 1304, 'related': 1305, \"'offensive\": 1306, 'eating': 1307, 'keeps': 1308, 'respect': 1309, 'formed': 1310, 'solidarity': 1311, 'settings': 1312, 'dark': 1313, 'pump': 1314, 'power': 1315, 'drove': 1316, 'eye': 1317, 'ate': 1318, 'transportation': 1319, 'apartment': 1320, 'shot': 1321, 'anywhere': 1322, 'helping': 1323, 'faces': 1324, 'truck': 1325, 'whenever': 1326, 'cousins': 1327, 'finish': 1328, 'seat': 1329, 'except': 1330, 'slow': 1331, 'traveling': 1332, 'travel': 1333, 'wanting': 1334, 'speak': 1335, 'trust': 1336, 'effects': 1337, 'congregation': 1338, 'keeping': 1339, 'tall': 1340, 'memory': 1341, 'lady': 1342, 'nervous': 1343, 'doesnt': 1344, 'minfong': 1345, 'garden': 1346, 'red': 1347, 'causes': 1348, 'deep': 1349, 'boyfriend': 1350, 'glad': 1351, 'parts': 1352, 'patiently': 1353, 'mine': 1354, 'particular': 1355, 'drinking': 1356, 'childrens': 1357, 'retake': 1358, 'research': 1359, 'factor': 1360, 'warmth': 1361, 'passing': 1362, 'complete': 1363, 'explicit': 1364, 'reminded': 1365, 'enjoyed': 1366, 'boys': 1367, 'glass': 1368, 'goal': 1369, 'belive': 1370, 'sisters': 1371, 'beat': 1372, 'jumped': 1373, 'lines': 1374, 'careers': 1375, 'admiration': 1376, 'fishing': 1377, 'innocence': 1378, 'burst': 1379, 'continued': 1380, 'straight': 1381, 'cost': 1382, 'bunch': 1383, 'explained': 1384, 'fear': 1385, 'aloud': 1386, 'throw': 1387, 'cars': 1388, 'impatient': 1389, 'period': 1390, 'peoples': 1391, 'cover': 1392, 'grandpa': 1393, 'radio': 1394, 'novel': 1395, 'anyway': 1396, 'neighbors': 1397, 'interest': 1398, 'gratefulness': 1399, 'sounds': 1400, 'dance': 1401, 'practice': 1402, 'represents': 1403, 'tied': 1404, 'leaves': 1405, 'present': 1406, 'becomes': 1407, 'suddenly': 1408, 'yelling': 1409, 'challenges': 1410, 'prevent': 1411, 'thirst': 1412, 'wonder': 1413, 'narrator': 1414, 'system': 1415, 'extended': 1416, 'libary': 1417, 'scary': 1418, 'smiled': 1419, 'reads': 1420, 'shoes': 1421, 'brothers': 1422, 'sorry': 1423, 'begins': 1424, 'blue': 1425, 'plans': 1426, 'bottles': 1427, 'fighting': 1428, 'month': 1429, 'grab': 1430, 'hungry': 1431, 'daughter': 1432, 'empty': 1433, 'he�s': 1434, 'accept': 1435, 'died': 1436, 'flamable': 1437, 'action': 1438, 'bright': 1439, 'willing': 1440, 'education': 1441, 'national': 1442, 'figure': 1443, 'rode': 1444, 'backdrop': 1445, 'may': 1446, 'avoid': 1447, 'individual': 1448, 'creating': 1449, 'auther': 1450, 'wide': 1451, 'honest': 1452, 'blow': 1453, 'included': 1454, 'available': 1455, 'influence': 1456, 'plus': 1457, 'connection': 1458, 'dream': 1459, 'staying': 1460, 'missed': 1461, 'surroundings': 1462, 'believes': 1463, 'theres': 1464, 'mainly': 1465, 'attitude': 1466, 'contained': 1467, 'art': 1468, 'countries': 1469, 'subjects': 1470, 'questions': 1471, 'fields': 1472, 'sudden': 1473, 'variety': 1474, 'dropped': 1475, 'instilled': 1476, 'eternally': 1477, 'forward': 1478, 'stronger': 1479, 'process': 1480, 'actions': 1481, 'women': 1482, 'fresh': 1483, 'involved': 1484, 'awkward': 1485, 'turns': 1486, ']': 1487, 'diffrent': 1488, 'ban': 1489, 'according': 1490, 'headed': 1491, '[': 1492, 'design': 1493, 'screaming': 1494, 'including': 1495, 'placed': 1496, 'fault': 1497, 'visit': 1498, 'streets': 1499, 'listened': 1500, 'pull': 1501, 'emotions': 1502, 't': 1503, 'educational': 1504, 'youth': 1505, 'teachers': 1506, 'honestly': 1507, 'similar': 1508, 'realizes': 1509, 'news': 1510, 'peace': 1511, 'loss': 1512, 'uncle': 1513, 'explaining': 1514, 'result': 1515, 'extreme': 1516, 'strongly': 1517, 'battery': 1518, 'unity': 1519, 'bigger': 1520, 'graphic': 1521, 'led': 1522, 'stomach': 1523, 'sick': 1524, 'ignore': 1525, 'describe': 1526, 'prevented': 1527, 'followed': 1528, 'summer': 1529, 'rusty': 1530, 'doors': 1531, 'tree': 1532, 'obsticles': 1533, 'forced': 1534, 'courageous': 1535, 'grown': 1536, 'ment': 1537, 'smiling': 1538, 'eachother': 1539, 'vulgar': 1540, 'map': 1541, 'pool': 1542, 'grape': 1543, 'thanked': 1544, 'legs': 1545, 'tower': 1546, 'business': 1547, 'presents': 1548, 'animals': 1549, 'crossed': 1550, 'direction': 1551, 'plane': 1552, 'becuase': 1553, 'aunt': 1554, 'element': 1555, 'citizens': 1556, 'challenge': 1557, 'killing': 1558, 'destination': 1559, 'ships': 1560, 'extra': 1561, 'expression': 1562, 'aromas': 1563, 'friendly': 1564, 'window': 1565, 'majority': 1566, 'audience': 1567, 'obviously': 1568, 'remind': 1569, 'comforting': 1570, 'generosity': 1571, 'helpful': 1572, 'fail': 1573, 'gracious': 1574, 'suppose': 1575, 'war': 1576, 'alright': 1577, 'plenty': 1578, 'attempted': 1579, 'solution': 1580, 'son': 1581, 'doctors': 1582, 'eleven': 1583, 'definitely': 1584, 'task': 1585, 'conversation': 1586, 'puts': 1587, 'hardships': 1588, 'thousands': 1589, 'tv': 1590, 'beating': 1591, 'weird': 1592, 'football': 1593, 'persons': 1594, 'raised': 1595, 'minute': 1596, 'absolutely': 1597, 'struggle': 1598, 'seven': 1599, 'offending': 1600, 'homework': 1601, 'turning': 1602, 'broken': 1603, 'doubt': 1604, \"''\": 1605, 'death': 1606, 'holding': 1607, 'he/she': 1608, 'notice': 1609, 'harmful': 1610, 'follow': 1611, 'deserted': 1612, 'corner': 1613, 'save': 1614, 'river': 1615, 'concern': 1616, 'strengthen': 1617, 'twenty': 1618, 'apart': 1619, 'someones': 1620, 'cases': 1621, '6': 1622, 'mentioned': 1623, 'weighted': 1624, 'heatstroke': 1625, 'spirit': 1626, 'lyrics': 1627, 'lakehurst': 1628, 'losing': 1629, 'forgot': 1630, 'shut': 1631, 'solve': 1632, '--': 1633, 'secondly': 1634, 'depends': 1635, 'librarys': 1636, 'birds': 1637, 'rude': 1638, '1937': 1639, 'hilarious': 1640, 'slavery': 1641, 'shortest': 1642, 'band': 1643, 'facts': 1644, 'snakes': 1645, 'protect': 1646, 'modify': 1647, 'woman': 1648, 'hitting': 1649, 'numerous': 1650, 'carry': 1651, 'includes': 1652, 'generation': 1653, 'field': 1654, 'kill': 1655, 'limited': 1656, 'push': 1657, 'bait': 1658, 'boat': 1659, 'oh': 1660, 'articles': 1661, 'encompassed': 1662, 'addition': 1663, 'packed': 1664, 'terrible': 1665, 'killed': 1666, 'breath': 1667, 'role': 1668, 'kinda': 1669, 'cared': 1670, 'opportunity': 1671, 'planned': 1672, 'customs': 1673, 'pumps': 1674, 'images': 1675, 'engineers': 1676, 'decisions': 1677, 'safely': 1678, 'relax': 1679, 'anyways': 1680, 'artist': 1681, 'theme': 1682, 'board': 1683, 'she�s': 1684, '’': 1685, 'falling': 1686, 'barely': 1687, 'bottle': 1688, 'fiction': 1689, 'perseverance': 1690, 'airship': 1691, 'source': 1692, 'card': 1693, 'misses': 1694, 'points': 1695, 'poor': 1696, 'hole': 1697, 'thus': 1698, 'coach': 1699, 'green': 1700, 'busy': 1701, 'elsewhere': 1702, 'sweet': 1703, 'curse': 1704, 'profanity': 1705, 'difference': 1706, '-': 1707, 'atop': 1708, 'bother': 1709, '“': 1710, 'balance': 1711, 'importance': 1712, 'success': 1713, 'conflict': 1714, 'include': 1715, 'current': 1716, 'relate': 1717, 'provide': 1718, 'somthing': 1719, 'enjoyable': 1720, 'hes': 1721, 'condition': 1722, 'teaching': 1723, 'realization': 1724, 'mixing': 1725, 'checking': 1726, 'date': 1727, 'totally': 1728, 'mistakes': 1729, 'classes': 1730, 'interests': 1731, 'general': 1732, 'limits': 1733, 'cheer': 1734, 'taller': 1735, 'pieces': 1736, 'funniest': 1737, 'sent': 1738, '”': 1739, 'popular': 1740, 'calling': 1741, 'sing': 1742, 'seconds': 1743, 'lessons': 1744, 'effected': 1745, 'potential': 1746, 'impact': 1747, 'teen': 1748, 'adventure': 1749, 'stick': 1750, 'heavy': 1751, 'multiple': 1752, 'grabbed': 1753, 'adding': 1754, 'sharp': 1755, 'frustrated': 1756, 'contains': 1757, 'heritage': 1758, 'normally': 1759, 'stating': 1760, 'describing': 1761, 'modern': 1762, 'mentions': 1763, 'novels': 1764, 'cycling': 1765, 'expect': 1766, 'sadness': 1767, 'hardly': 1768, \"'the\": 1769, 'earlier': 1770, 'nowhere': 1771, 'writer': 1772, 'enjoying': 1773, 'miss': 1774, 'silly': 1775, 'uncensored': 1776, 'relaxed': 1777, 'cook': 1778, 'newspaper': 1779, 'shower': 1780, 'shed': 1781, 'alive': 1782, 'choices': 1783, 'constructing': 1784, 'los': 1785, 'necessary': 1786, 'racist': 1787, 'afraid': 1788, 'deer': 1789, 'adds': 1790, 'hung': 1791, 'foreign': 1792, 'chair': 1793, 'forth': 1794, 'style': 1795, 'following': 1796, 'angeles': 1797, 'harm': 1798, 'list': 1799, 'physical': 1800, 'destined': 1801, 'fulfill': 1802, 'treated': 1803, 'lucky': 1804, 'again�': 1805, 'wan': 1806, 'peaceful': 1807, 'innapropriate': 1808, 'somethings': 1809, 'immediately': 1810, 'encountered': 1811, 'wear': 1812, 'generations': 1813, 'allows': 1814, 'rock': 1815, 'besides': 1816, 'effort': 1817, 'trees': 1818, 'writers': 1819, 'rent': 1820, 'higher': 1821, 'obsticle': 1822, 'scenes': 1823, 'healthy': 1824, 'isn�t': 1825, 'obvious': 1826, 'hurting': 1827, 'offer': 1828, 'jump': 1829, 'proves': 1830, 'mistake': 1831, 'anger': 1832, 'bond': 1833, 'forgotten': 1834, 'study': 1835, 'duties': 1836, 'designed': 1837, \"'all\": 1838, 'color': 1839, 'buying': 1840, 'differently': 1841, 'box': 1842, 'constructed': 1843, 'banning': 1844, 'series': 1845, 'aircraft': 1846, 'picking': 1847, 'matters': 1848, 'cyclists': 1849, 'shirt': 1850, 'offened': 1851, 'breaking': 1852, 'company': 1853, 'tries': 1854, 'fixed': 1855, 'aware': 1856, 'closed': 1857, 'beach': 1858, 'bag': 1859, 'chrysler': 1860, 'wondering': 1861, 'sometime': 1862, 'eight': 1863, 'shape': 1864, 'hoping': 1865, 'acceptable': 1866, 'temperature': 1867, 'further': 1868, 'rating': 1869, '�a': 1870, 'flew': 1871, 'comments': 1872, 'mess': 1873, 'tumbleweeds': 1874, 'press': 1875, 'countless': 1876, 'depressed': 1877, 'screamed': 1878, 'seriously': 1879, 'pants': 1880, 'succeed': 1881, 'daily': 1882, 'hood': 1883, 'pop': 1884, 'sports': 1885, 'acid': 1886, 'uncomfortable': 1887, 'porch': 1888, 'continues': 1889, 'maturity': 1890, 'perfectly': 1891, 'hopes': 1892, 'welcoming': 1893, 'meeting': 1894, 'disaster': 1895, 'teenager': 1896, 'repeatedly': 1897, 'america': 1898, 'pedal': 1899, 'bloom': 1900, 'pushed': 1901, 'spanish': 1902, 'argue': 1903, 'cried': 1904, 'medicine': 1905, 'girlfriend': 1906, 'hunting': 1907, 'force': 1908, 'scene': 1909, 'ratings': 1910, 'understood': 1911, 'service': 1912, 'wasnt': 1913, 'inapropriate': 1914, 'physically': 1915, 'taste': 1916, 'believed': 1917, 'rush': 1918, 'fill': 1919, 'unique': 1920, 'expressed': 1921, 'recently': 1922, 'warning': 1923, 'blame': 1924, 'grass': 1925, 'concluding': 1926, 'expresses': 1927, 'original': 1928, 'relatives': 1929, 'space': 1930, 'welcomed': 1931, 'won': 1932, 'drank': 1933, 'couch': 1934, 'rider': 1935, 'necessarily': 1936, 'couldnt': 1937, 'wake': 1938, 'rules': 1939, 'anchor': 1940, 'paid': 1941, 'june.�': 1942, 'remembered': 1943, 'nine': 1944, 'hotel': 1945, 'focus': 1946, 'races': 1947, 'luck': 1948, 'block': 1949, 'driver': 1950, 'won�t': 1951, 'candy': 1952, 'quit': 1953, 'mall': 1954, 'alcohol': 1955, '1,250': 1956, 'cd': 1957, 'romance': 1958, 'wall': 1959, 'breakfast': 1960, 'selflessness': 1961, 'surrounding': 1962, 'shelve': 1963, 'damage': 1964, 'difficulties': 1965, 'biker': 1966, 'swing': 1967, 'rushing': 1968, 'blocked': 1969, 'stroke': 1970, 'search': 1971, 'faith': 1972, 'represent': 1973, 'stared': 1974, 'welcome': 1975, 'crack': 1976, 'smart': 1977, 'unwittingly': 1978, 'powerful': 1979, 'sides': 1980, 'cyclist�s': 1981, 'send': 1982, 'perhaps': 1983, 'prove': 1984, 'event': 1985, 'restrictions': 1986, 'cares': 1987, 'ridiculously': 1988, 'usual': 1989, 'emotion': 1990, 'names': 1991, 'certainly': 1992, 'cake': 1993, 'prepared': 1994, 'win': 1995, 'remain': 1996, 'note': 1997, 'location': 1998, 'runs': 1999, 'clock': 2000, 'neighbor': 2001, 'customers': 2002, 'calls': 2003, 'quick': 2004, 'shes': 2005, 'foul': 2006, 'driver�s': 2007, 'tolerant': 2008, 'sleeping': 2009, '�flat': 2010, 'unfair': 2011, 'adapting': 2012, 'mental': 2013, 'drug': 2014, 'childern': 2015, 'arm': 2016, 'tend': 2017, 'dear': 2018, 'confused': 2019, 'heads': 2020, 'experienced': 2021, 'random': 2022, 'size': 2023, 'builder': 2024, 'image': 2025, 'ruin': 2026, 'scent': 2027, 'swim': 2028, 'racial': 2029, 'apparent': 2030, 'genre': 2031, 'struggled': 2032, 'bottom': 2033, 'crash': 2034, 'occurred': 2035, 'seats': 2036, 'disappointed': 2037, 'close-knit': 2038, 'navy': 2039, 'careful': 2040, 'background': 2041, 'dessert': 2042, 'symbolizes': 2043, 'agreed': 2044, 'italian': 2045, 'signs': 2046, 'acts': 2047, 'fully': 2048, 'disturbing': 2049, 'relief': 2050, 'dressed': 2051, 'basis': 2052, 'cursing': 2053, 'opposite': 2054, 'famous': 2055, 'adjust': 2056, 'natural': 2057, 'basketball': 2058, 'exhausted': 2059, 'laying': 2060, 'adore': 2061, 'lake': 2062, 'responsibility': 2063, 'balloon': 2064, 'somehow': 2065, 'letter': 2066, 'walks': 2067, 'pulling': 2068, 'silent': 2069, 'annoying': 2070, 'cute': 2071, 'required': 2072, 'constant': 2073, 'dead': 2074, 'decides': 2075, 'biking': 2076, 'plays': 2077, 'viewed': 2078, 'intended': 2079, 'smell': 2080, 'appreciation': 2081, 'sharing': 2082, 'restricted': 2083, 'luckily': 2084, 'struggles': 2085, 'unable': 2086, 'landed': 2087, 'proved': 2088, 'hardest': 2089, 'various': 2090, 'untill': 2091, 'balloons': 2092, 'bumpy': 2093, 'she�ll': 2094, 'touch': 2095, 'population': 2096, 'selfless': 2097, 'hopefully': 2098, 'camping': 2099, 'introduced': 2100, 'drinks': 2101, 'hundreds': 2102, 'forceful': 2103, 'dislike': 2104, 'yard': 2105, 'title': 2106, 'judge': 2107, 'everytime': 2108, 'passes': 2109, 'viewing': 2110, 'stage': 2111, 'track': 2112, 'impressed': 2113, 'treat': 2114, 'mention': 2115, 'approve': 2116, 'mentally': 2117, 'thrown': 2118, 'rings': 2119, 'exact': 2120, 'aspect': 2121, 'answered': 2122, '��': 2123, 'rushed': 2124, 'childs': 2125, 'among': 2126, 'depending': 2127, 'walls': 2128, 'scream': 2129, 'planting': 2130, 'differnt': 2131, 'soul': 2132, 'feast': 2133, 'bringing': 2134, 'managed': 2135, 'saved': 2136, 'comedy': 2137, 'paragraphs': 2138, 'bud': 2139, 'awesome': 2140, 'computers': 2141, 'swimming': 2142, 'provided': 2143, 'beacuse': 2144, 'classroom': 2145, 'factors': 2146, 'wich': 2147, 'yeah': 2148, 'argument': 2149, 'symbol': 2150, 'page': 2151, 'gorgeous': 2152, 'correct': 2153, 'attempts': 2154, 'expected': 2155, 'completed': 2156, 'dangers': 2157, 'planning': 2158, 'failure': 2159, 'seperate': 2160, 'dreams': 2161, 'facing': 2162, 'smiles': 2163, 'giggle': 2164, 'sacrificed': 2165, 'figured': 2166, 'published': 2167, 'librarians': 2168, 'beleive': 2169, 'unfortunately': 2170, 'somewhat': 2171, 'draw': 2172, 'cultural': 2173, 'occur': 2174, 'influenced': 2175, 'behavior': 2176, 'wet': 2177, 'gear': 2178, 'slide': 2179, 'sounded': 2180, 'sell': 2181, 'mud': 2182, 'brown': 2183, 'tantalizing': 2184, 'online': 2185, 'yell': 2186, 'located': 2187, 'math': 2188, 'repeat': 2189, 'values': 2190, 'happend': 2191, 'sky': 2192, 'teaches': 2193, 'sand': 2194, 'giant': 2195, 'loose': 2196, 'brain': 2197, 'accomplish': 2198, 'travelling': 2199, 'chances': 2200, 'smooth': 2201, 'potentially': 2202, 'extent': 2203, 'tomorrow': 2204, 'acting': 2205, 'selves': 2206, '�it': 2207, 'humble': 2208, 'hurry': 2209, 'fifteen': 2210, 'mass': 2211, 'hopeless': 2212, 'attached': 2213, 'approached': 2214, 'gun': 2215, 'social': 2216, 'quietly': 2217, 'intense': 2218, 'weigh': 2219, 'desk': 2220, 'displayed': 2221, 'relieved': 2222, 'civilization': 2223, 'ft': 2224, 'nudity': 2225, 'pavement': 2226, 'stops': 2227, 'considering': 2228, 'blowing': 2229, 'hardworking': 2230, 'locked': 2231, 'technology': 2232, 'spires': 2233, 'pride': 2234, 'religions': 2235, '�in': 2236, 'spending': 2237, 'mph': 2238, 'missing': 2239, 'horror': 2240, 'skin': 2241, 'innocent': 2242, 'stainless': 2243, 'stable': 2244, 'videos': 2245, 'exciting': 2246, 'cuss': 2247, 'entertain': 2248, 'restaurant': 2249, 'drama': 2250, 'characters': 2251, 'details': 2252, 'sold': 2253, 'dirty': 2254, 'nearby': 2255, 'cream': 2256, 'throwing': 2257, 'pushing': 2258, 'humans': 2259, 'regularly': 2260, '�she': 2261, 'counter': 2262, 'shoot': 2263, 'cruel': 2264, 'shy': 2265, 'celebrate': 2266, 'shade': 2267, 'observation': 2268, 'shell': 2269, 'climate': 2270, 'dose': 2271, 'serve': 2272, 'fights': 2273, 'blooms': 2274, 'dancing': 2275, 'and/or': 2276, 'shopping': 2277, 'segregation': 2278, 'report': 2279, 'pages': 2280, 'super': 2281, 'nation': 2282, 'responsible': 2283, 'todays': 2284, 'pizza': 2285, 'designing': 2286, 'weekend': 2287, 'gain': 2288, 'morals': 2289, 'ridiculous': 2290, 'cross': 2291, 'round': 2292, 'genres': 2293, 'mail': 2294, 'dirt': 2295, 'spoke': 2296, 'refueling': 2297, 'gift': 2298, 'appreciative': 2299, 'hilly': 2300, 'degrees': 2301, 'cracking': 2302, 'rivers': 2303, 'entirely': 2304, 'deemed': 2305, 'individuals': 2306, 'i�ll': 2307, 'whom': 2308, 'church': 2309, 'invited': 2310, 'covered': 2311, 'despair': 2312, 'i�ve': 2313, 'escape': 2314, 'selection': 2315, 'prohibited': 2316, 'count': 2317, 'challenging': 2318, 'tension': 2319, 'mile': 2320, 'emotional': 2321, '�this': 2322, 'troubles': 2323, 'hiding': 2324, 'resources': 2325, 'hopeful': 2326, 'nasty': 2327, 'teenage': 2328, 'imagination': 2329, 'rooms': 2330, 'isnt': 2331, 'freely': 2332, 'remembering': 2333, 'disappointment': 2334, '�there': 2335, 'noise': 2336, 'embarrassed': 2337, 'weighed': 2338, 'surrounded': 2339, 'personality': 2340, 'enjoyment': 2341, 'realizing': 2342, 'pines': 2343, 'furthermore': 2344, 'awhile': 2345, 'stands': 2346, 'dumb': 2347, 'sway': 2348, 'quality': 2349, 'artists': 2350, 'perspective': 2351, 'lay': 2352, 'religious': 2353, 'substance': 2354, 'wearing': 2355, 'soft': 2356, 'sence': 2357, 'blooming': 2358, 'hat': 2359, 'millions': 2360, 'sunny': 2361, 'shots': 2362, 'god': 2363, 'sorts': 2364, 'chocolate': 2365, 'belief': 2366, 'reaches': 2367, 'equipment': 2368, '1930': 2369, 'expressing': 2370, 'enviroment': 2371, 'friendships': 2372, 'legal': 2373, 'endure': 2374, 'construct': 2375, 'cities': 2376, 'surprised': 2377, 'position': 2378, 'stepped': 2379, 'rate': 2380, 'leg': 2381, 'shiny': 2382, 'presented': 2383, 'witch': 2384, 'stoped': 2385, 'burn': 2386, 'curious': 2387, 'shock': 2388, 'airport': 2389, 'rain': 2390, 'college': 2391, 'carter': 2392, 'safty': 2393, 'butt': 2394, 'spire': 2395, 'dried': 2396, 'leads': 2397, 'teeth': 2398, 'animal': 2399, 'twice': 2400, 'soda': 2401, 'train': 2402, 'joyful': 2403, 'charge': 2404, 'floors': 2405, 'dull': 2406, 'base': 2407, 'vacation': 2408, 'newark': 2409, 'pair': 2410, 'ordered': 2411, 'planted': 2412, 'elementary': 2413, 'tons': 2414, 'blind': 2415, 'ther': 2416, 'deserve': 2417, 'rocks': 2418, 'affecting': 2419, 'consideration': 2420, 'concert': 2421, 'enter': 2422, 'forms': 2423, 'surprise': 2424, 'moves': 2425, 'atleast': 2426, 'van': 2427, 'certian': 2428, 'happier': 2429, 'alike': 2430, 'sources': 2431, 'singing': 2432, 'dress': 2433, 'object': 2434, 'architect': 2435, 'dads': 2436, 'houses': 2437, 'happyness': 2438, 'mask': 2439, 'appreciate': 2440, 'concerned': 2441, 'wild': 2442, 'activity': 2443, 'health': 2444, 'detail': 2445, 'dating': 2446, 'thirty': 2447, 'gases': 2448, 'offered': 2449, 'evening': 2450, 'fails': 2451, 'activities': 2452, 'account': 2453, 'display': 2454, 'bikes': 2455, 'lights': 2456, 'staring': 2457, 'native': 2458, 'inspiration': 2459, 'traffic': 2460, 'seasons': 2461, 'difficulty': 2462, 'hazard': 2463, 'greatfulness': 2464, 'thankfulness': 2465, 'heading': 2466, 'welch�s': 2467, 'twelve': 2468, 'becasue': 2469, 'steps': 2470, 'enormous': 2471, 'librarie': 2472, 'complained': 2473, 'lower': 2474, 'adventures': 2475, 'actual': 2476, 'aspects': 2477, 'provides': 2478, 'waste': 2479, 'hills.�': 2480, 'bell': 2481, 'roller': 2482, 'hug': 2483, 'siblings': 2484, 'poeple': 2485, 'newspapers': 2486, 'pole': 2487, 'circled': 2488, 'asks': 2489, 'crowded': 2490, 'speaking': 2491, 'brave': 2492, 'ahead�': 2493, 'altitude': 2494, 'june�': 2495, 'explode': 2496, 'moms': 2497, 'contact': 2498, 'option': 2499, 'unlike': 2500, 'crowd': 2501, 'messages': 2502, 'differences': 2503, 'realy': 2504, 'possibility': 2505, '�and': 2506, '+': 2507, 'blocks': 2508, 'greater': 2509, 'expanded': 2510, 'afternoon': 2511, 'unpredictable': 2512, 'wondered': 2513, 'inappropiate': 2514, 'separate': 2515, 'raise': 2516, 'earth': 2517, 'historical': 2518, 'exist': 2519, 'fence': 2520, 'solved': 2521, 'total': 2522, 'opening': 2523, 'don': 2524, 'depressing': 2525, 'description': 2526, 'milk': 2527, 'gym': 2528, 'flight': 2529, 'results': 2530, 'speaker': 2531, 'dealing': 2532, 'weak': 2533, 'audiences': 2534, 'alway': 2535, 'woods': 2536, 'eighteen': 2537, 'repetition': 2538, 'buds': 2539, 'trail': 2540, 'permission': 2541, 'holds': 2542, 'kindness': 2543, 'demonstration': 2544, 'vary': 2545, 'dying': 2546, 'response': 2547, 'airplanes': 2548, 'weeds': 2549, 'ears': 2550, 'tasted': 2551, 'his/her': 2552, 'incident': 2553, 'player': 2554, 'uplifting': 2555, 'haven�t': 2556, 'benefit': 2557, 'toy': 2558, 'dentist': 2559, 'cat': 2560, 'pack': 2561, 'pedaling': 2562, 'controversial': 2563, 'shortcut': 2564, 'comforted': 2565, 't.v': 2566, 'slightly': 2567, 'wave': 2568, 'lifestyle': 2569, 'meals': 2570, 'strangers': 2571, 'cussing': 2572, 'silence': 2573, 'outcome': 2574, 'carefully': 2575, 'vows': 2576, 'shelter': 2577, 'objects': 2578, 'ear': 2579, 'swear': 2580, 'blond': 2581, 'strict': 2582, 'originally': 2583, 'thirteen': 2584, 'winch': 2585, 'massive': 2586, 'film': 2587, 'concerns': 2588, 'porches': 2589, 'windy': 2590, 'educate': 2591, 'ease': 2592, 'threat': 2593, 'site': 2594, 'refugees': 2595, 'childeren': 2596, 'theory': 2597, 'upstairs': 2598, 'searching': 2599, 'returned': 2600, 'entitled': 2601, 'significant': 2602, 'aunts': 2603, 'roll': 2604, 'announced': 2605, 'reaching': 2606, 'removal': 2607, 'previous': 2608, 'sacrifices': 2609, 'freedoms': 2610, 'dogs': 2611, 'product': 2612, 'equal': 2613, 'valuable': 2614, 'directly': 2615, 'memior': 2616, 'lifetime': 2617, 'ramshackle': 2618, 'remembers': 2619, 'wether': 2620, 'regular': 2621, 'center': 2622, 'min': 2623, 'crippling': 2624, 'highest': 2625, 'entered': 2626, 'pebbles': 2627, 'stones': 2628, 'spirits': 2629, 'expensive': 2630, 'limit.�': 2631, 'hospital': 2632, 'wow': 2633, 'papers': 2634, 'violently': 2635, 'moral': 2636, 'literary': 2637, 'promise': 2638, 'paint': 2639, 'adapted': 2640, 'pointless': 2641, 'embarrassing': 2642, 'joined': 2643, 'exploded': 2644, 'homes': 2645, 'joking': 2646, 'containing': 2647, 'cell': 2648, 'wise': 2649, 'accepted': 2650, 'connected': 2651, 'unhappy': 2652, 'aren�t': 2653, 'passion': 2654, 'proper': 2655, 'pouring': 2656, 'south': 2657, 'per': 2658, 'bet': 2659, 'chrome-nickel': 2660, 'selling': 2661, 'importantly': 2662, 'jumping': 2663, 'hall': 2664, 'purchase': 2665, 'basic': 2666, 'eased': 2667, 'garage': 2668, 'seek': 2669, 'explore': 2670, 'tickets': 2671, 'entertaining': 2672, 'giggling': 2673, 'finaly': 2674, 'deeply': 2675, 'vow': 2676, 'ring': 2677, 'spread': 2678, 'thriving': 2679, 'hated': 2680, 'posed': 2681, 'fourth': 2682, 'enjoys': 2683, 'cleaning': 2684, 'humorous': 2685, 'highway': 2686, 'discovered': 2687, 'useful': 2688, 'cycle': 2689, 'sixth': 2690, 'picks': 2691, 'motivation': 2692, 'shocked': 2693, 'quotes': 2694, 'comment': 2695, 'everyones': 2696, 'refreshing': 2697, 'contents': 2698, 'hills�': 2699, 'bedroom': 2700, 'disappeared': 2701, 'fifth': 2702, 'hurts': 2703, 'longest': 2704, 'otherwise': 2705, \"should'nt\": 2706, 'range': 2707, 'corral': 2708, 'breeze': 2709, 'stars': 2710, 'sink': 2711, 'quad': 2712, 'burning': 2713, 'abhor': 2714, 'cleaned': 2715, 'blast': 2716, 'gardening': 2717, 'skill': 2718, 'bags': 2719, 'phrase': 2720, 'american': 2721, 'flames': 2722, 'suggested': 2723, 'grand': 2724, 'outlook': 2725, 'popcorn': 2726, 'buys': 2727, 'acted': 2728, 'arrive': 2729, 'fashion': 2730, 'belong': 2731, 'trash': 2732, 'spark': 2733, 'adjusting': 2734, 'wiped': 2735, 'literally': 2736, 'react': 2737, 'fourteen': 2738, 'i�d': 2739, 'speaks': 2740, 'locker': 2741, 'libaries': 2742, 'security': 2743, 'blown': 2744, 'beauty': 2745, 'electric': 2746, 'portrayed': 2747, 'manner': 2748, 'plain': 2749, 'hurtful': 2750, 'worlds': 2751, 'someday': 2752, 'soccer': 2753, 'lighter': 2754, 'magizines': 2755, 'now.�': 2756, 'tear': 2757, 'focused': 2758, 'birthdays': 2759, 'parking': 2760, 'arrival': 2761, 'wars': 2762, 'o': 2763, 'mountain': 2764, '@percent': 2765, 'breathe': 2766, 'route': 2767, '12': 2768, 'collapse': 2769, 'elements': 2770, 'keys': 2771, 'coffee': 2772, 'options': 2773, 'toilet': 2774, 'crime': 2775, 'teachings': 2776, \"'family\": 2777, 'shooting': 2778, 'handed': 2779, 'sips': 2780, 'choosing': 2781, 'ipod': 2782, 'weren�t': 2783, 'floating': 2784, 'knock': 2785, 'players': 2786, 'goin': 2787, 'non': 2788, 'compared': 2789, 'aircrafts': 2790, 'informed': 2791, 'parties': 2792, 'pm': 2793, 'appointment': 2794, 'didn': 2795, 'warming': 2796, 'anxious': 2797, 'suggest': 2798, 'guns': 2799, 'arguments': 2800, 'appropiate': 2801, '�town�': 2802, 'kick': 2803, 'expand': 2804, 'hadn�t': 2805, 'received': 2806, 'themes': 2807, 'join': 2808, 'messing': 2809, 'ticket': 2810, 'rang': 2811, 'creation': 2812, 'kicked': 2813, 'clothing': 2814, 'expecting': 2815, 'desire': 2816, 'yours': 2817, 'respectful': 2818, 'hello': 2819, 'overcoming': 2820, 'begining': 2821, 'slowed': 2822, 'grades': 2823, 'viewers': 2824, 'badly': 2825, 'hallway': 2826, 'gratefull': 2827, 'products': 2828, 'survival': 2829, 'beyond': 2830, 'arrives': 2831, '�then': 2832, 'shouted': 2833, 'risky': 2834, 'wished': 2835, 'tumble': 2836, 'trick': 2837, 'hoped': 2838, 'naked': 2839, 'him/her': 2840, 'classic': 2841, 'achieve': 2842, 'wat': 2843, 'tastes': 2844, 'financially': 2845, 'stressed': 2846, 'convey': 2847, 'reluctantly': 2848, 'metal': 2849, 'science': 2850, 'concept': 2851, 'overcame': 2852, 'largest': 2853, 'm': 2854, 'pure': 2855, 'develop': 2856, 'peers': 2857, 'split': 2858, 'symbolize': 2859, 'connect': 2860, 'lonely': 2861, 'para': 2862, 'purposes': 2863, 'standards': 2864, 'skeleton': 2865, 'relates': 2866, 'accepting': 2867, 'drigibles': 2868, 'colors': 2869, 'scenery': 2870, 'cheerful': 2871, 'appeared': 2872, 'benefits': 2873, 'spit': 2874, 'lungs': 2875, 'alegria': 2876, '�one': 2877, 'flavor': 2878, 'winning': 2879, 'educated': 2880, 'catching': 2881, 'granted': 2882, 'shift': 2883, 'assignment': 2884, 'grin': 2885, 'temporarily': 2886, 'touching': 2887, 'rolled': 2888, 'fought': 2889, 'saftey': 2890, 'murder': 2891, 'immigrated': 2892, 'hid': 2893, 'destroy': 2894, 'understandable': 2895, 'tail': 2896, 'inspired': 2897, 'leader': 2898, 'camera': 2899, 'shoulder': 2900, 'greeted': 2901, 'evidence': 2902, 'admit': 2903, 'amounts': 2904, 'lifes': 2905, 'cedar': 2906, 'teams': 2907, '1961': 2908, 'offencive': 2909, 'president': 2910, 'determine': 2911, 'cencorship': 2912, 'clue': 2913, 'prepare': 2914, 'grows': 2915, 'gathered': 2916, 'experts': 2917, 'coaster': 2918, 'dehydrate': 2919, 'notes': 2920, 'assigned': 2921, 'covers': 2922, 'payed': 2923, 'apparently': 2924, 'climb': 2925, 'screen': 2926, 'yesterday': 2927, 'rusted': 2928, 'hi': 2929, 'exited': 2930, 'offinsive': 2931, 'excitement': 2932, 'elses': 2933, 'row': 2934, 'noone': 2935, 'vote': 2936, 'dislikes': 2937, '�ghost': 2938, 'spin': 2939, 'risks': 2940, 'swinging': 2941, 'emotionally': 2942, 'negatively': 2943, 'atmosphere': 2944, 'fake': 2945, 'throught': 2946, 'stopping': 2947, 'tryed': 2948, 'suffer': 2949, 'projects': 2950, 'knocked': 2951, 'decades': 2952, 'unrealistic': 2953, 'proven': 2954, 'meal': 2955, 'license': 2956, 'nights': 2957, 'knees': 2958, 'designer': 2959, 'fond': 2960, 'partner': 2961, 'drunk': 2962, 'edge': 2963, 'tiny': 2964, 'encounters': 2965, 'returning': 2966, 'gang': 2967, 'platform': 2968, 'summary': 2969, 'actors': 2970, 'insight': 2971, 'toll': 2972, 'worries': 2973, 'accomplished': 2974, 'thay': 2975, 'admires': 2976, 'member': 2977, 'greatfull': 2978, 'windows': 2979, 'complications': 2980, 'brand': 2981, 'flow': 2982, 'rope': 2983, 'publish': 2984, 'desperate': 2985, 'struggling': 2986, 'ignored': 2987, 'false': 2988, '�you': 2989, 'double': 2990, 'inform': 2991, 'owner': 2992, 'growth': 2993, 'discouraged': 2994, 'learns': 2995, 'label': 2996, 'hey': 2997, 'select': 2998, 'restroom': 2999, 'calmed': 3000, 'copy': 3001, 'secure': 3002, 'celebrated': 3003, 'birth': 3004, 'target': 3005, 'appreciates': 3006, 'slept': 3007, 'slower': 3008, 'cards': 3009, 'reaction': 3010, 'marked': 3011, 'debate': 3012, 'whoever': 3013, 'lie': 3014, 'inviting': 3015, 'paying': 3016, \"'i\": 3017, 'specifically': 3018, 'market': 3019, 'december': 3020, 'wood': 3021, 'closing': 3022, 'cure': 3023, 'bound': 3024, 'troubled': 3025, 'rule': 3026, 'traditions': 3027, 'emphasize': 3028, 'feared': 3029, 'hidden': 3030, 'gender': 3031, 'reasoning': 3032, 'circumstances': 3033, 'resource': 3034, 'suit': 3035, '�short': 3036, 'lab': 3037, 'supports': 3038, 'reminder': 3039, 'fate': 3040, 'lamest': 3041, 'ahold': 3042, 'sacrafice': 3043, 'trys': 3044, 'timers': 3045, 'successfully': 3046, 'previously': 3047, 'wash': 3048, 'mothers': 3049, 'touched': 3050, 'value': 3051, 'befor': 3052, 'puncture': 3053, '�almost': 3054, 'closest': 3055, 'zeppelin': 3056, 'shaky': 3057, 'parked': 3058, 'punished': 3059, 'bite': 3060, 'kind.�': 3061, 'wrap': 3062, 'flaws': 3063, 'terms': 3064, 'fifty': 3065, 'sweating': 3066, 'length': 3067, 'watches': 3068, 'scare': 3069, 'toys': 3070, 'million': 3071, 'essential': 3072, 'thanking': 3073, 'designers': 3074, 'pleased': 3075, 'labeled': 3076, 'regardless': 3077, 'generally': 3078, 'rise': 3079, '55': 3080, 'controlled': 3081, '�not': 3082, 'tight': 3083, 'bump': 3084, 'civilians': 3085, 'swaying': 3086, 'jail': 3087, 'automatically': 3088, 'diamond': 3089, 'lift': 3090, 'sooner': 3091, 'settled': 3092, 'bout': 3093, 'bothered': 3094, 'opinon': 3095, 'log': 3096, 'version': 3097, 'shifted': 3098, 'replace': 3099, 'kiss': 3100, 'arent': 3101, 'colored': 3102, 'it.�': 3103, 'hysterically': 3104, 'slipped': 3105, 'seventh': 3106, 'stranger': 3107, '�at': 3108, 'worrying': 3109, 'competition': 3110, 'uncles': 3111, 'hotter': 3112, 'ultimately': 3113, 'instantly': 3114, 'forty': 3115, 'denied': 3116, 'lifted': 3117, 'sips.�': 3118, 'impractical': 3119, 'preventing': 3120, 'ill': 3121, 'slaves': 3122, 'promised': 3123, 'exclaimed': 3124, 'term': 3125, 'cooked': 3126, '102': 3127, '.�': 3128, 'mountains': 3129, 'supplies': 3130, 'meap': 3131, 'regret': 3132, 'blossom': 3133, 'staff': 3134, 'citizen': 3135, 'satisfied': 3136, 'odd': 3137, 'wore': 3138, 'indeed': 3139, 'involve': 3140, 'greenhouse': 3141, 'record': 3142, 'hearts': 3143, 'p': 3144, 'survived': 3145, 'afford': 3146, 'rocky': 3147, 'infront': 3148, 'evil': 3149, 'impression': 3150, 'mum': 3151, 'manager': 3152, 'troubling': 3153, 'burned': 3154, 'pleasant': 3155, 'choir': 3156, 'pumped': 3157, 'quicker': 3158, 'stare': 3159, 'sentences': 3160, 'advanced': 3161, 'improve': 3162, 'bitter': 3163, 'mixed': 3164, 'effective': 3165, 'tradition': 3166, 'becuse': 3167, 'requires': 3168, 'pink': 3169, 'systems': 3170, 'surely': 3171, 'stumbled': 3172, 'jeans': 3173, 'wating': 3174, 'town�': 3175, 'questioned': 3176, 'carried': 3177, 'developed': 3178, 'accidents': 3179, 'minor': 3180, 'messed': 3181, 'arose': 3182, 'libray': 3183, 'puppies': 3184, 'freaking': 3185, 'cheeks': 3186, 'cop': 3187, 'sucking': 3188, 'withstand': 3189, 'forcing': 3190, 'believing': 3191, 'sang': 3192, 'winters': 3193, 'arguing': 3194, 'ours': 3195, 'shortly': 3196, 'cabin': 3197, 'dollar': 3198, 'suck': 3199, 'abuse': 3200, 'bye': 3201, 'lawn': 3202, 'star': 3203, 'compare': 3204, 'babysitter': 3205, 'controversy': 3206, 'beside': 3207, 'court': 3208, 'visiting': 3209, 'gossip': 3210, 'oppinion': 3211, 'fantastic': 3212, 'apologized': 3213, 'framed': 3214, 'sake': 3215, 'eggs': 3216, 'truely': 3217, 'sould': 3218, 'restrict': 3219, 'hazards': 3220, 'disrespectful': 3221, 'pleasure': 3222, 'vast': 3223, 'downstairs': 3224, 'steep': 3225, 'contagious': 3226, 'driveway': 3227, 'understands': 3228, 'incredibly': 3229, 'ups': 3230, 'combined': 3231, 'returns': 3232, 'discover': 3233, 'optimistic': 3234, 'flip': 3235, 'ton': 3236, 'anytime': 3237, 'fork': 3238, 'explosion': 3239, 'capable': 3240, 'generous': 3241, 'laid': 3242, 'smaller': 3243, 'framing': 3244, 'zone': 3245, 'governor': 3246, 'depend': 3247, 'tool': 3248, 'fingers': 3249, 'wheel': 3250, 'puppy': 3251, 'bust': 3252, 'derigibles': 3253, 'skate': 3254, 'limiting': 3255, 'intrest': 3256, 'favor': 3257, 'destroying': 3258, 'pointed': 3259, 'uncontrollably': 3260, 'fan': 3261, 'knit': 3262, 'plot': 3263, 'tag': 3264, 'annoyed': 3265, 'dies': 3266, 'gary': 3267, 'model': 3268, 'nerves': 3269, 'mirage': 3270, 'sorrow': 3271, 'observations': 3272, 'cracked': 3273, 'you�re': 3274, 'sigh': 3275, 'sheltered': 3276, 'shorts': 3277, 'panic': 3278, 'singer': 3279, 'loosing': 3280, 'encounter': 3281, 'themself': 3282, 'innappropriate': 3283, 'complaints': 3284, 'score': 3285, 'reflect': 3286, 'recent': 3287, 'conversations': 3288, 'hell': 3289, 'unstable': 3290, 'served': 3291, 'evident': 3292, 'certin': 3293, 'raining': 3294, 'influences': 3295, 'steal': 3296, 'whose': 3297, 'cats': 3298, 'claim': 3299, 'relaxing': 3300, '�that': 3301, 'heavily': 3302, 'nose': 3303, 'attend': 3304, 'pornography': 3305, '�saeng': 3306, 'rapidly': 3307, 'directed': 3308, 'beneficial': 3309, 'whe': 3310, 'aside': 3311, 'websites': 3312, 'average': 3313, 'displays': 3314, 'promote': 3315, 'cope': 3316, 'qualities': 3317, 'confines': 3318, 'larger': 3319, 'arguement': 3320, 'boss': 3321, 'protest': 3322, 'babies': 3323, '�wide': 3324, 'swept': 3325, 'statements': 3326, 'storm': 3327, 'attach': 3328, 'stung': 3329, 'creative': 3330, 'ar': 3331, 'float': 3332, 'reply': 3333, 'twist': 3334, 'bicycle': 3335, 'listens': 3336, 'structural': 3337, 'shoulders': 3338, 'guitar': 3339, 'gratefullness': 3340, 'blanket': 3341, 'hardship': 3342, 'nonfiction': 3343, 'pee': 3344, 'tent': 3345, 'cozy': 3346, 'strain': 3347, 'bowl': 3348, 'degree': 3349, 'disappear': 3350, 'magizine': 3351, 'blew': 3352, 'deeper': 3353, 'ideals': 3354, 'diverse': 3355, 'ladies': 3356, 'properly': 3357, 'fallen': 3358, 'tire': 3359, 'wilber�s': 3360, 'steady': 3361, 'worn': 3362, 'nowadays': 3363, 'parental': 3364, 'shake': 3365, 'bonds': 3366, 'tables': 3367, 'accidentally': 3368, 'severe': 3369, 'selfish': 3370, 'becaus': 3371, 'pond': 3372, \"would'nt\": 3373, 'crude': 3374, 'comparing': 3375, 'destruction': 3376, 'memorable': 3377, 'ignorant': 3378, 'thankfull': 3379, 'graders': 3380, 'household': 3381, 'oozed': 3382, 'brackish': 3383, 'yea': 3384, 'apply': 3385, 'strengthening': 3386, 'advantage': 3387, 'porn': 3388, 'tested': 3389, 'mystery': 3390, 'levels': 3391, 'encourage': 3392, 'illuminated': 3393, 'politics': 3394, 'figuring': 3395, 'naturally': 3396, 'painful': 3397, 'safer': 3398, 'efforts': 3399, 'shook': 3400, 'norm': 3401, 'ful': 3402, 'exercise': 3403, 'plate': 3404, 'cast': 3405, 'reward': 3406, 'par': 3407, 'me.�': 3408, 'temperatures': 3409, 'volleyball': 3410, 'rarely': 3411, 'finger': 3412, 'answers': 3413, 'admired': 3414, 'town.�': 3415, 'bumps': 3416, 'unpatient': 3417, 'convinced': 3418, 'voices': 3419, 'chip': 3420, 'testing': 3421, 'portrays': 3422, 'chooses': 3423, 'bars': 3424, 'captain': 3425, 'ordinary': 3426, 'challenged': 3427, 'opportunities': 3428, 'geting': 3429, 'assume': 3430, 'liking': 3431, 'hates': 3432, 'occupied': 3433, 'ta': 3434, 'slid': 3435, 'chores': 3436, 'leading': 3437, 'happiest': 3438, 'sale': 3439, 'suited': 3440, '1956': 3441, 'judgement': 3442, 'meat': 3443, 'situated': 3444, 'tracks': 3445, 'match': 3446, 'aroma': 3447, 'wright': 3448, 'you�ll': 3449, 'sport': 3450, 'horse': 3451, 'patent': 3452, 'mule': 3453, 'gentlemen': 3454, 'involves': 3455, 'restricting': 3456, 'appealing': 3457, 'monitor': 3458, 'colorful': 3459, 'shine': 3460, 'incredible': 3461, 'goodbye': 3462, 'slurs': 3463, 'guardian': 3464, 'bar': 3465, 'completly': 3466, 'stressful': 3467, 'correctly': 3468, 'consequences': 3469, 'prefer': 3470, 'overlooked': 3471, 'relized': 3472, 'craft': 3473, 'makeing': 3474, 'chips': 3475, 'contributed': 3476, 'amused': 3477, 'reflects': 3478, 'extremly': 3479, 'depleting': 3480, 'author�s': 3481, 'coast': 3482, \"'bad\": 3483, 'theirs': 3484, 'installed': 3485, 'spare': 3486, 'landscape': 3487, 'boost': 3488, 'organized': 3489, 'films': 3490, 'expose': 3491, 'tremendous': 3492, 'prohibiting': 3493, 'familys': 3494, 'released': 3495, 'dangle': 3496, 'lock': 3497, 'crashing': 3498, 'constitution': 3499, 'grandfather': 3500, 'devastating': 3501, 'individuality': 3502, 'glanced': 3503, 'practically': 3504, 'stays': 3505, 'post': 3506, 'appeal': 3507, 'classmates': 3508, 'unknown': 3509, 'solutions': 3510, 'reasonable': 3511, 'tripped': 3512, 'prints': 3513, 'tiring': 3514, 'muscles': 3515, 'pretend': 3516, 'checks': 3517, 'tools': 3518, 'modifying': 3519, 'cencored': 3520, 'goverment': 3521, 'th': 3522, 'vowing': 3523, 'references': 3524, 'mins': 3525, 'nap': 3526, 'ironic': 3527, 'rebirth': 3528, 'immagrants': 3529, 'shoe': 3530, 'hyper': 3531, 'eve': 3532, 'sticking': 3533, 'adored': 3534, 'heck': 3535, 'discuss': 3536, 'surrogate': 3537, 'wife': 3538, 'abhor-': 3539, 'boots': 3540, 'supported': 3541, 'breaks': 3542, 'chest': 3543, 'vivid': 3544, 'glue': 3545, 'unbearable': 3546, 'receive': 3547, 'frequently': 3548, 'hydrated': 3549, 'hook': 3550, 'coaches': 3551, 'giggled': 3552, 'gained': 3553, 'graced': 3554, 'delicious': 3555, 'chairs': 3556, 'gather': 3557, 'grader': 3558, 'warn': 3559, 'herd': 3560, 'barren': 3561, 'responded': 3562, 'inspire': 3563, 'battle': 3564, 'therefor': 3565, 'compassion': 3566, 'recognize': 3567, 'refuel': 3568, 'comedian': 3569, 'divided': 3570, 'monkey': 3571, 'career': 3572, 'smelled': 3573, 'peice': 3574, 'planet': 3575, 'chuckle': 3576, 'private': 3577, 'cheered': 3578, 'progress': 3579, 'awful': 3580, 'poisonous': 3581, 'sadly': 3582, 'hop': 3583, 'portray': 3584, 'stumble': 3585, 'observed': 3586, 'meaningful': 3587, 'tooken': 3588, 'shoud': 3589, 'tragic': 3590, 'fills': 3591, 'protected': 3592, 'boyfriends': 3593, 'distracted': 3594, 'lips': 3595, 'ensure': 3596, 'gentle': 3597, 'wheather': 3598, 'struck': 3599, 'werent': 3600, 'gifts': 3601, 'inner': 3602, 'pointing': 3603, 'builds': 3604, '<': 3605, 'climbed': 3606, 'bench': 3607, 'unsuccessful': 3608, 'oldest': 3609, 'hangout': 3610, 'bank': 3611, 'pacient': 3612, 'rip': 3613, 'gosh': 3614, 'bridge': 3615, 'wated': 3616, 'comforts': 3617, 'flipped': 3618, 'concerning': 3619, 'occured': 3620, 'fixing': 3621, 'shouldn�t': 3622, 'spots': 3623, '1970': 3624, 'circle': 3625, 'hopped': 3626, 'unjust': 3627, 'complicated': 3628, 'stubborn': 3629, 'desirable': 3630, 'demonstrates': 3631, 'siting': 3632, 'shall': 3633, 'complains': 3634, 'tube': 3635, 'diversity': 3636, 'summers': 3637, 'explanation': 3638, 'useless': 3639, 'authority': 3640, 'foods': 3641, 'gum': 3642, 'faint': 3643, 'vision': 3644, 'aviation': 3645, 'sophomore': 3646, 'offence': 3647, 'pot': 3648, 'sweaty': 3649, 'racing': 3650, 'visited': 3651, 'decrease': 3652, 'restriction': 3653, 'junior': 3654, 'pays': 3655, 'homesick': 3656, 'encouraged': 3657, 'soil': 3658, 'ha': 3659, 'packing': 3660, 'rented': 3661, 'sum': 3662, 'maintain': 3663, 'speeds': 3664, 'realistic': 3665, 'phones': 3666, 'amazed': 3667, 'adores': 3668, 'gangs': 3669, 'gradually': 3670, '�over': 3671, 'ocean': 3672, 'experiencing': 3673, 'eager': 3674, 'heartwarming': 3675, 'imagined': 3676, 'styles': 3677, 'honey': 3678, '�old': 3679, 'discussed': 3680, 'hits': 3681, 'ad': 3682, 'beings': 3683, 'reference': 3684, 'peak': 3685, 'selfs': 3686, 'conserve': 3687, 'vocabulary': 3688, 'unacceptable': 3689, 'communicate': 3690, 'punctured': 3691, 'zeppelins': 3692, 'unexpected': 3693, 'collection': 3694, 'alternative': 3695, 'respected': 3696, 'release': 3697, 'purple': 3698, '�are': 3699, 'happily': 3700, 'motivated': 3701, 'tours': 3702, 'begging': 3703, 'reveals': 3704, 'youngest': 3705, '�i�m': 3706, 'farm': 3707, 'parants': 3708, 'tip': 3709, 'dealt': 3710, 'studying': 3711, 'elevation': 3712, 'opens': 3713, 'offers': 3714, 'lying': 3715, 'precious': 3716, 'peer': 3717, 'doctor�s': 3718, 'crashed': 3719, 'bear': 3720, 'tests': 3721, 'property': 3722, 'exchange': 3723, 'directors': 3724, 'v': 3725, 'gently': 3726, 'frown': 3727, 'sums': 3728, 'sugar': 3729, 'mirror': 3730, 'slammed': 3731, 'mark': 3732, 'treats': 3733, 'lest': 3734, 'freshman': 3735, 'old-timers': 3736, 'creativity': 3737, 'expectations': 3738, 'lt': 3739, 'require': 3740, 'produced': 3741, 'wen': 3742, 'studied': 3743, 'wii': 3744, 'gate': 3745, 'lies': 3746, 'carrying': 3747, 'refers': 3748, 'upbeat': 3749, 'stock': 3750, 'nodded': 3751, 'begun': 3752, 'fairly': 3753, 'deciding': 3754, 'teammates': 3755, 'giggles': 3756, 'postpone': 3757, 'involving': 3758, 'beep': 3759, 'popped': 3760, 'signed': 3761, 'lasted': 3762, 'noises': 3763, 'phrases': 3764, 'northern': 3765, 'landlord': 3766, 'conflicts': 3767, 'satisfaction': 3768, 'hade': 3769, 'conveyed': 3770, 'personalities': 3771, 'eliminate': 3772, 'ugly': 3773, 'shorter': 3774, 'smallest': 3775, 'freak': 3776, 'dishes': 3777, 'shirts': 3778, 'bodies': 3779, 'commercials': 3780, 'regarding': 3781, 'glance': 3782, '�no': 3783, 'melting': 3784, 'latest': 3785, 'bouncing': 3786, 'hike': 3787, 'trips': 3788, 'sticker': 3789, 'reduce': 3790, 'horrific': 3791, 're': 3792, 'treating': 3793, 'retaking': 3794, 'knee': 3795, 'album': 3796, 'baseball': 3797, 'protecting': 3798, 'surface': 3799, 'haveing': 3800, 'distinctive': 3801, 'relieve': 3802, 'visual': 3803, 'hurried': 3804, 'cheese': 3805, 'hopelessness': 3806, 'blankets': 3807, 'arrangement': 3808, 'grate': 3809, 'bend': 3810, 'listed': 3811, 'fuel': 3812, 'exit': 3813, 'raced': 3814, 'travels': 3815, '�high': 3816, 'valid': 3817, 'harmless': 3818, 'weed': 3819, 'bay': 3820, 'pg': 3821, 'finnaly': 3822, 'budding�': 3823, 'intelligent': 3824, 'nicely': 3825, 'shocking': 3826, 'throat': 3827, 'injured': 3828, 'agrees': 3829, 'horizon': 3830, 'skating': 3831, 'bath': 3832, 'context': 3833, 'sits': 3834, 'deserves': 3835, 'constructors': 3836, 'development': 3837, 'feed': 3838, 'drives': 3839, 'softball': 3840, 'narration': 3841, 'humid': 3842, 'deserved': 3843, 'unnecessary': 3844, 'peed': 3845, 'flock': 3846, 'fulfilled': 3847, 'direct': 3848, 'exerpt': 3849, 'rare': 3850, 'occasion': 3851, 'pitch': 3852, 'drew': 3853, 'skinny': 3854, 'thick': 3855, 'immature': 3856, 'now�': 3857, 'observe': 3858, 'classics': 3859, 'avoided': 3860, 'confusion': 3861, 'logical': 3862, 'rental': 3863, 'kidding': 3864, 'maria': 3865, 'chemical': 3866, 'removes': 3867, 'yards': 3868, 'additional': 3869, 'instances': 3870, 'awake': 3871, 'counting': 3872, 'conveys': 3873, '�i-i': 3874, 'refill': 3875, 'monster': 3876, 'companies': 3877, 'political': 3878, 'felling': 3879, 'installation': 3880, 'campground': 3881, 'bird': 3882, 'cotton': 3883, 'prevailed': 3884, 'nurse': 3885, 'acceptance': 3886, 'loaded': 3887, 'state.�': 3888, 'centuries': 3889, 'pocket': 3890, 'mama': 3891, 'hears': 3892, 'pig': 3893, 'traits': 3894, \"'but\": 3895, 'raising': 3896, 'busted': 3897, '11': 3898, 'wishing': 3899, 'he�d': 3900, 'licence': 3901, 'wings': 3902, 'shaking': 3903, 'goals': 3904, 'relating': 3905, 'producers': 3906, 'produce': 3907, 'whent': 3908, 'sore': 3909, 'currently': 3910, 'snack': 3911, 'attack': 3912, 'belongs': 3913, 'overt': 3914, 'shore': 3915, 'singers': 3916, 'depression': 3917, 'unsure': 3918, 'down�': 3919, 'non-fiction': 3920, 'caution': 3921, 'drops': 3922, \"'to\": 3923, 'nightmares': 3924, 'dirigables': 3925, 'checkout': 3926, 'monitored': 3927, 'furious': 3928, 'guide': 3929, 'behave': 3930, 'hooked': 3931, 'ties': 3932, 'implies': 3933, 'lane': 3934, 'chuckled': 3935, 'progressed': 3936, 'brick': 3937, 'rollercoaster': 3938, 'remarks': 3939, 'solid': 3940, 'miserable': 3941, 'burger': 3942, 'researching': 3943, 'depicts': 3944, 'mouths': 3945, 'deadly': 3946, '1930s': 3947, 'forest': 3948, 'tricks': 3949, 'standard': 3950, '/': 3951, 'practiced': 3952, 'yellow': 3953, 'beggining': 3954, 'tips': 3955, 'arrow': 3956, 'bow': 3957, 'leaf': 3958, 'docks': 3959, 'crap': 3960, 'slightest': 3961, 'backyard': 3962, 'sticks': 3963, 'cookies': 3964, 'categories': 3965, '�but': 3966, 'deck': 3967, '�gary': 3968, 'catastrophic': 3969, 'address': 3970, 'falls': 3971, 'soaked': 3972, 'beginnings': 3973, 'nephew': 3974, 'authour': 3975, 'ashamed': 3976, 'heights': 3977, 'obtain': 3978, 'mom�s': 3979, 'definetly': 3980, 'supporting': 3981, 'twins': 3982, 'randomly': 3983, 'rely': 3984, 'parentheses': 3985, 'readings': 3986, 'firstly': 3987, 'owned': 3988, 'ya': 3989, 'bible': 3990, 'exposure': 3991, 'married': 3992, 'mission': 3993, 'consisted': 3994, 'backs': 3995, 'spoken': 3996, 'tossed': 3997, 'grocery': 3998, 'expressions': 3999}\n{'prompt_words': [[[37, 272, 2141, 160, 3829, 2873, 621, 4], [1023, 1, 2232, 201, 2141, 837, 724, 37, 4], [825, 600, 1317, 1, 270, 37, 1091, 312, 1, 870, 37, 94, 250, 37, 377, 2185, 37, 4], [292, 175, 698, 4], [2917, 2441, 37, 2237, 170, 76, 2141, 772, 76, 1, 1773, 342, 1, 105, 174, 4], [662, 2066, 1273, 1779, 107, 384, 1337, 2141, 37, 4], [1, 824, 594, 4]], [[218, 125, 4], [122, 72, 73, 340, 1007, 124, 124, 288, 262, 4], [143, 409, 73, 262, 275, 2714, 79, 949, 143, 160, 304, 4], [54, 261, 262, 122, 4], [917, 938, 74, 4], [662, 1, 704, 1779, 1, 1, 218, 125, 4], [201, 211, 256, 54, 114, 130, 192, 428, 4], [289, 214, 243, 82, 1023, 2378, 1, 2800, 650, 3272, 229, 4]], [[662, 2547, 736, 281, 165, 319, 106, 4], [2547, 1715, 1274, 704, 1023, 413, 4]], [[90, 271, 131, 84, 4], [190, 108, 150, 814, 820, 309, 864, 739, 341, 483, 210, 472, 96, 148, 4], [662, 2547, 736, 74, 308, 84, 131, 4], [2547, 1715, 2252, 1274, 84, 1023, 698, 4]], [[1526, 92, 245, 74, 151, 4], [1023, 985, 1, 1180, 462, 151, 4]], [[756, 445, 1526, 178, 149, 113, 107, 56, 180, 354, 250, 99, 189, 4], [1023, 985, 1, 1180, 462, 445, 4]], [[662, 248, 4], [133, 405, 1090, 2008, 4], [133, 144, 650, 1965, 314, 1243, 4], [51, 1796, 662, 84, 76, 133, 662, 84, 76, 161, 120, 133, 662, 84, 91, 248, 4]], [[438, 2873, 158, 4], [213, 161, 109, 158, 1642, 1153, 239, 37, 4], [80, 37, 201, 158, 310, 352, 485, 4], [279, 564, 84, 158, 51, 1555, 352, 4]]], 'prompt_ids': [1, 2, 3, 4, 5, 6, 7, 8], 'max_sentnum': 8, 'max_sentlen': 18}\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip freeze > /kaggle/working/requirements.txt","metadata":{"execution":{"iopub.status.busy":"2024-11-01T05:57:50.959854Z","iopub.execute_input":"2024-11-01T05:57:50.960284Z","iopub.status.idle":"2024-11-01T05:57:53.661113Z","shell.execute_reply.started":"2024-11-01T05:57:50.960237Z","shell.execute_reply":"2024-11-01T05:57:53.659782Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# read essays and prompts\ntrain_data, dev_data, test_data = read_essays_prompts(read_configs, prompt_data, prompt_pos_data, pos_vocab) ","metadata":{"execution":{"iopub.status.busy":"2024-11-01T05:57:53.665501Z","iopub.execute_input":"2024-11-01T05:57:53.665923Z","iopub.status.idle":"2024-11-01T06:03:37.151788Z","shell.execute_reply.started":"2024-11-01T05:57:53.665877Z","shell.execute_reply":"2024-11-01T06:03:37.150577Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":" pos_x size: 9513\n readability_x size: 9513\n pos_x size: 1680\n readability_x size: 1680\n pos_x size: 1783\n readability_x size: 1783\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"The line OOV number =190, OOV ratio = 0.047512 indicates that 190 words from your vocabulary did not have corresponding entries in the GloVe embeddings, making up around 4.75% of the vocabulary.\nThese OOV words will likely receive a placeholder vector, such as zeros or a random initialization.","metadata":{}},{"cell_type":"code","source":"if pretrained_embedding:\n    embedd_dict, embedd_dim, _ = load_word_embedding_dict(embedding_path)\n    embedd_matrix = build_embedd_table(word_vocab, embedd_dict, embedd_dim, caseless=True)\n    embed_table = [embedd_matrix]\nelse:\n    embed_table = None","metadata":{"execution":{"iopub.status.busy":"2024-11-01T06:05:05.507740Z","iopub.execute_input":"2024-11-01T06:05:05.508512Z","iopub.status.idle":"2024-11-01T06:05:13.630629Z","shell.execute_reply.started":"2024-11-01T06:05:05.508465Z","shell.execute_reply":"2024-11-01T06:05:13.629415Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Loading GloVe ...\nOOV number =190, OOV ratio = 0.047512\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Certainly! Here’s a breakdown of the input and output data structures:\n\n### Input Data Explanation\n\n1. **`X_train_pos`, `X_dev_pos`, `X_test_pos`**:\n   - These represent Part-of-Speech (POS) tagged sequences for the essays.\n   - Each is structured as `(number of samples, max_sentnum * max_sentlen)`, where:\n     - `max_sentnum` is the maximum number of sentences in any essay.\n     - `max_sentlen` is the maximum number of words in any sentence.\n   - This padding ensures that all essays are represented by sequences of the same length, allowing batch processing.\n\n2. **`X_train_prompt`, `X_dev_prompt`, `X_test_prompt`**:\n   - These represent the prompt words, with the same padding structure as the essay POS tags.\n   - Since the model may need to account for the prompt (e.g., the essay topic) when scoring, the prompt words are treated as an input feature.\n\n3. **`X_train_prompt_pos`, `X_dev_prompt_pos`, `X_test_prompt_pos`**:\n   - These are POS-tagged versions of the prompt words, structured similarly to the essay data.\n   - They help the model learn any linguistic patterns associated with prompts and how these might influence essay scoring.\n\n4. **`X_train_readability`, `X_dev_readability`, `X_test_readability`**:\n   - These are readability scores for each essay, with 35 features each.\n   - They offer additional essay characteristics that reflect various readability metrics, providing insights into linguistic complexity, sentence structure, vocabulary usage, etc.\n\n5. **`X_train_linguistic_features`, `X_dev_linguistic_features`, `X_test_linguistic_features`**:\n   - These are handcrafted linguistic features with 52 values per essay.\n   - Examples could include sentence length, word variety, spelling errors, or grammar complexity metrics, all of which can influence an essay’s quality.\n\n6. **`X_train_attribute_rel`, `X_dev_attribute_rel`, `X_test_attribute_rel`**:\n   - These are attribute relevance masks shaped as `(samples, number of attributes)`.\n   - They help the model focus on relevant aspects of the essays for scoring. For example, an essay could be scored on attributes like structure, grammar, or creativity, depending on the prompt’s requirements.\n\n### Output Data Explanation\n\n1. **`Y_train`, `Y_dev`, `Y_test`**:\n   - These are the scaled scores for each essay across multiple scoring attributes, represented as `(samples, number of attributes)`.\n   - Each attribute might represent a different scoring criterion, such as grammar, cohesion, or creativity.\n   - The scores have been scaled down to fall within a consistent range (e.g., between 0 and 1), allowing the model to predict values in a normalized range.\n\n### How These Inputs and Outputs Are Used in the Model\n\nIn a typical model architecture for this setup:\n- **Embedding Layers**: For `X_train_pos`, `X_train_prompt`, and `X_train_prompt_pos`, embeddings or POS embeddings can be applied, translating each word/POS tag into a vector space.\n- **Feature Concatenation**: The different inputs (readability, linguistic features, prompt, POS tags) are concatenated to form a comprehensive feature set for each essay.\n- **Attention or Attribute Masking**: `X_train_attribute_rel` helps direct the model’s focus to specific attributes that are most relevant to the prompt.\n- **Output Layer**: The model outputs `Y_train` as predicted scores for each attribute, comparing with `Y_test` in evaluation.\n\nThis setup allows the model to capture both linguistic and structural essay features, enhancing the ability to predict scores across multiple grading dimensions.","metadata":{}},{"cell_type":"code","source":"max_sentlen = max(train_data['max_sentlen'], dev_data['max_sentlen'], test_data['max_sentlen'])\nmax_sentnum = max(train_data['max_sentnum'], dev_data['max_sentnum'], test_data['max_sentnum'])\nprompt_max_sentlen = prompt_data['max_sentlen']\nprompt_max_sentnum = prompt_data['max_sentnum']\n\nprint('max sent length: {}'.format(max_sentlen))\nprint('max sent num: {}'.format(max_sentnum))\nprint('max prompt sent length: {}'.format(prompt_max_sentlen))\nprint('max prompt sent num: {}'.format(prompt_max_sentnum))\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T06:05:30.928828Z","iopub.execute_input":"2024-11-01T06:05:30.929308Z","iopub.status.idle":"2024-11-01T06:05:30.937088Z","shell.execute_reply.started":"2024-11-01T06:05:30.929263Z","shell.execute_reply":"2024-11-01T06:05:30.935884Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"max sent length: 50\nmax sent num: 97\nmax prompt sent length: 18\nmax prompt sent num: 8\n","output_type":"stream"}]},{"cell_type":"code","source":"# scale final scores\n\ntrain_data['y_scaled'] = get_scaled_down_scores(train_data['data_y'], train_data['prompt_ids'])\ndev_data['y_scaled'] = get_scaled_down_scores(dev_data['data_y'], dev_data['prompt_ids'])\ntest_data['y_scaled'] = get_scaled_down_scores(test_data['data_y'], test_data['prompt_ids'])\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T06:05:49.651146Z","iopub.execute_input":"2024-11-01T06:05:49.651700Z","iopub.status.idle":"2024-11-01T06:05:49.839559Z","shell.execute_reply.started":"2024-11-01T06:05:49.651656Z","shell.execute_reply":"2024-11-01T06:05:49.838371Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"X_train_pos = pad_hierarchical_text_sequences(train_data['pos_x'], max_sentnum, max_sentlen)\nX_dev_pos = pad_hierarchical_text_sequences(dev_data['pos_x'], max_sentnum, max_sentlen)\nX_test_pos = pad_hierarchical_text_sequences(test_data['pos_x'], max_sentnum, max_sentlen)\n\nX_train_pos = X_train_pos.reshape((X_train_pos.shape[0], X_train_pos.shape[1] * X_train_pos.shape[2]))\nX_dev_pos = X_dev_pos.reshape((X_dev_pos.shape[0], X_dev_pos.shape[1] * X_dev_pos.shape[2]))\nX_test_pos = X_test_pos.reshape((X_test_pos.shape[0], X_test_pos.shape[1] * X_test_pos.shape[2]))\n\nX_train_prompt = pad_hierarchical_text_sequences(train_data['prompt_words'], max_sentnum, max_sentlen)\nX_dev_prompt = pad_hierarchical_text_sequences(dev_data['prompt_words'], max_sentnum, max_sentlen)\nX_test_prompt = pad_hierarchical_text_sequences(test_data['prompt_words'], max_sentnum, max_sentlen)\n\nX_train_prompt = X_train_prompt.reshape((X_train_prompt.shape[0], X_train_prompt.shape[1] * X_train_prompt.shape[2]))\nX_dev_prompt = X_dev_prompt.reshape((X_dev_prompt.shape[0], X_dev_prompt.shape[1] * X_dev_prompt.shape[2]))\nX_test_prompt = X_test_prompt.reshape((X_test_prompt.shape[0], X_test_prompt.shape[1] * X_test_prompt.shape[2]))\n\nX_train_prompt_pos = pad_hierarchical_text_sequences(train_data['prompt_pos'], max_sentnum, max_sentlen)\nX_dev_prompt_pos = pad_hierarchical_text_sequences(dev_data['prompt_pos'], max_sentnum, max_sentlen)\nX_test_prompt_pos = pad_hierarchical_text_sequences(test_data['prompt_pos'], max_sentnum, max_sentlen)\n\nX_train_prompt_pos = X_train_prompt_pos.reshape((X_train_prompt_pos.shape[0], X_train_prompt_pos.shape[1] * X_train_prompt_pos.shape[2]))\nX_dev_prompt_pos = X_dev_prompt_pos.reshape((X_dev_prompt_pos.shape[0], X_dev_prompt_pos.shape[1] * X_dev_prompt_pos.shape[2]))\nX_test_prompt_pos = X_test_prompt_pos.reshape((X_test_prompt_pos.shape[0], X_test_prompt_pos.shape[1] * X_test_prompt_pos.shape[2]))\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T06:05:52.509640Z","iopub.execute_input":"2024-11-01T06:05:52.510065Z","iopub.status.idle":"2024-11-01T06:05:55.132734Z","shell.execute_reply.started":"2024-11-01T06:05:52.510024Z","shell.execute_reply":"2024-11-01T06:05:55.131747Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"X_train_linguistic_features = np.array(train_data['features_x'])\nX_dev_linguistic_features = np.array(dev_data['features_x'])\nX_test_linguistic_features = np.array(test_data['features_x'])\n\nX_train_readability = np.array(train_data['readability_x'])\nX_dev_readability = np.array(dev_data['readability_x'])\nX_test_readability = np.array(test_data['readability_x'])\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T06:05:55.134686Z","iopub.execute_input":"2024-11-01T06:05:55.135414Z","iopub.status.idle":"2024-11-01T06:05:55.241920Z","shell.execute_reply.started":"2024-11-01T06:05:55.135357Z","shell.execute_reply":"2024-11-01T06:05:55.240601Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"Y_train = np.array(train_data['y_scaled'])\nY_dev = np.array(dev_data['y_scaled'])\nY_test = np.array(test_data['y_scaled'])","metadata":{"execution":{"iopub.status.busy":"2024-11-01T06:05:56.239221Z","iopub.execute_input":"2024-11-01T06:05:56.239692Z","iopub.status.idle":"2024-11-01T06:05:56.267270Z","shell.execute_reply.started":"2024-11-01T06:05:56.239650Z","shell.execute_reply":"2024-11-01T06:05:56.266183Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"X_train_attribute_rel = get_attribute_masks(Y_train)\nX_dev_attribute_rel = get_attribute_masks(Y_dev)\nX_test_attribute_rel = get_attribute_masks(Y_test)\n\nprint('================================')\nprint('X_train_pos: ', X_train_pos.shape)\nprint('X_train_prompt_words: ', X_train_prompt.shape)\nprint('X_train_prompt_pos: ', X_train_prompt_pos.shape)\nprint('X_train_readability: ', X_train_readability.shape)\nprint('X_train_ling: ', X_train_linguistic_features.shape)\nprint('X_train_attribute_rel: ', X_train_attribute_rel.shape)\nprint('Y_train: ', Y_train.shape)\n\nprint('================================')\nprint('X_dev_pos: ', X_dev_pos.shape)\nprint('X_dev_prompt_words: ', X_dev_prompt.shape)\nprint('X_dev_prompt_pos: ', X_dev_prompt_pos.shape)\nprint('X_dev_readability: ', X_dev_readability.shape)\nprint('X_dev_ling: ', X_dev_linguistic_features.shape)\nprint('X_dev_attribute_rel: ', X_dev_attribute_rel.shape)\nprint('Y_dev: ', Y_dev.shape)\n\nprint('================================')\nprint('X_test_pos: ', X_test_pos.shape)\nprint('X_test_prompt_words: ', X_test_prompt.shape)\nprint('X_test_prompt_pos: ', X_test_prompt_pos.shape)\nprint('X_test_readability: ', X_test_readability.shape)\nprint('X_test_ling: ', X_test_linguistic_features.shape)\nprint('X_test_attribute_rel: ', X_test_attribute_rel.shape)\nprint('Y_test: ', Y_test.shape)\nprint('================================')\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T06:05:59.185085Z","iopub.execute_input":"2024-11-01T06:05:59.186181Z","iopub.status.idle":"2024-11-01T06:05:59.200098Z","shell.execute_reply.started":"2024-11-01T06:05:59.186130Z","shell.execute_reply":"2024-11-01T06:05:59.198936Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"================================\nX_train_pos:  (9513, 4850)\nX_train_prompt_words:  (9513, 4850)\nX_train_prompt_pos:  (9513, 4850)\nX_train_readability:  (9513, 35)\nX_train_ling:  (9513, 52)\nX_train_attribute_rel:  (9513, 9)\nY_train:  (9513, 9)\n================================\nX_dev_pos:  (1680, 4850)\nX_dev_prompt_words:  (1680, 4850)\nX_dev_prompt_pos:  (1680, 4850)\nX_dev_readability:  (1680, 35)\nX_dev_ling:  (1680, 52)\nX_dev_attribute_rel:  (1680, 9)\nY_dev:  (1680, 9)\n================================\nX_test_pos:  (1783, 4850)\nX_test_prompt_words:  (1783, 4850)\nX_test_prompt_pos:  (1783, 4850)\nX_test_readability:  (1783, 35)\nX_test_ling:  (1783, 52)\nX_test_attribute_rel:  (1783, 9)\nY_test:  (1783, 9)\n================================\n","output_type":"stream"}]},{"cell_type":"code","source":"print(X_dev_pos[0])\nprint(X_dev_prompt_pos[0])","metadata":{"execution":{"iopub.status.busy":"2024-11-01T06:12:39.082953Z","iopub.execute_input":"2024-11-01T06:12:39.083853Z","iopub.status.idle":"2024-11-01T06:12:39.090026Z","shell.execute_reply.started":"2024-11-01T06:12:39.083804Z","shell.execute_reply":"2024-11-01T06:12:39.088823Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"[4 2 5 ... 0 0 0]\n[16  7  7 ...  0  0  0]\n","output_type":"stream"}]},{"cell_type":"code","source":"dev_data['prompt_pos'][0]","metadata":{"execution":{"iopub.status.busy":"2024-11-01T06:13:13.755113Z","iopub.execute_input":"2024-11-01T06:13:13.755601Z","iopub.status.idle":"2024-11-01T06:13:13.763974Z","shell.execute_reply.started":"2024-11-01T06:13:13.755550Z","shell.execute_reply":"2024-11-01T06:13:13.762670Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"[[16, 7, 7, 3, 3, 20, 5, 5, 6, 12, 7, 3, 5, 8], [5, 5, 5, 7, 5, 5, 8]]"},"metadata":{}}]},{"cell_type":"code","source":"dev_data['y_scaled'][0]","metadata":{"execution":{"iopub.status.busy":"2024-11-01T06:10:56.436039Z","iopub.execute_input":"2024-11-01T06:10:56.436599Z","iopub.status.idle":"2024-11-01T06:10:56.444240Z","shell.execute_reply.started":"2024-11-01T06:10:56.436554Z","shell.execute_reply":"2024-11-01T06:10:56.443108Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"[0.75, 0.5, -1, -1, -1, -1, 0.5, 0.5, 0.5]"},"metadata":{}}]},{"cell_type":"code","source":"dev_data['readability_x'][0]","metadata":{"execution":{"iopub.status.busy":"2024-11-01T06:08:52.650515Z","iopub.execute_input":"2024-11-01T06:08:52.650998Z","iopub.status.idle":"2024-11-01T06:08:52.659391Z","shell.execute_reply.started":"2024-11-01T06:08:52.650957Z","shell.execute_reply":"2024-11-01T06:08:52.658181Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"array([0.59565176, 0.41567585, 0.52881241, 0.31776822, 0.46624325,\n       0.478611  , 0.48412292, 0.32608696, 0.35442793, 0.48915323,\n       0.71380471, 0.39204545, 0.35      , 0.40467261, 0.33896757,\n       0.33544304, 0.34565217, 0.46575342, 0.35      , 0.        ,\n       0.28205128, 0.24193548, 0.29577465, 0.22727273, 0.26666667,\n       0.07692308, 0.21428571, 0.32307692, 0.22222222, 0.16666667,\n       0.        , 0.3       , 0.        , 0.        , 0.14285714])"},"metadata":{}}]},{"cell_type":"code","source":"dev_data['features_x'][0] # linguistic features / handcrafted features","metadata":{"execution":{"iopub.status.busy":"2024-11-01T06:09:34.959233Z","iopub.execute_input":"2024-11-01T06:09:34.959719Z","iopub.status.idle":"2024-11-01T06:09:34.968401Z","shell.execute_reply.started":"2024-11-01T06:09:34.959677Z","shell.execute_reply":"2024-11-01T06:09:34.967170Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"[0.9113381674357284,\n 0.37864864864864844,\n 0.13036962365591392,\n 0.20262390670553934,\n 0.02884128858154832,\n 0.3386581469648562,\n 0.3481152993348115,\n 0.27272727272727276,\n 0.5,\n 0.21428571428571425,\n 0.08333333333333333,\n 0.25,\n 0.3225806451612903,\n 0.41558441558441556,\n 0.4382207939063992,\n 0.14100185528756956,\n 0.17666666666666667,\n 0.455641592920354,\n 0.5714285714285714,\n 0.4285714285714285,\n 0.0,\n 0.9737648985143633,\n 0.0,\n 0.06629834254143603,\n 0.27071823204419854,\n 0.32320441988950255,\n 0.0,\n 0.0,\n 0.0,\n 0.17403314917127063,\n 0.06629834254143603,\n 0.5318600368324126,\n 0.03867403314917102,\n 0.19521178637200623,\n 0.06156274664561914,\n 0.2817679558011043,\n 0.2900552486187845,\n 0.3845303867403317,\n 0.1988950276243093,\n 0.0,\n 0.23941068139963156,\n 0.07213014119091456,\n 0.0,\n 0.0,\n 0.5805556019206267,\n 0.2394106813996303,\n 0.6332544067350698,\n 0.30386740331491713,\n 0.15469613259668505,\n 0.17403314917127063,\n 0.0911602209944745,\n 0.2917127071823204]"},"metadata":{}}]},{"cell_type":"code","source":"train_features_list = [X_train_pos, X_train_prompt, X_train_prompt_pos, X_train_linguistic_features, X_train_readability]\ndev_features_list = [X_dev_pos, X_dev_prompt, X_dev_prompt_pos, X_dev_linguistic_features, X_dev_readability]\ntest_features_list = [X_test_pos, X_test_prompt, X_test_prompt_pos, X_test_linguistic_features, X_test_readability]\n     \n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T06:30:15.072396Z","iopub.execute_input":"2024-11-01T06:30:15.072854Z","iopub.status.idle":"2024-11-01T06:30:15.079042Z","shell.execute_reply.started":"2024-11-01T06:30:15.072812Z","shell.execute_reply":"2024-11-01T06:30:15.077738Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"dev_features_list","metadata":{"execution":{"iopub.status.busy":"2024-11-01T06:30:26.809623Z","iopub.execute_input":"2024-11-01T06:30:26.810056Z","iopub.status.idle":"2024-11-01T06:30:26.820023Z","shell.execute_reply.started":"2024-11-01T06:30:26.810015Z","shell.execute_reply":"2024-11-01T06:30:26.818893Z"},"trusted":true},"execution_count":62,"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"[array([[ 4,  2,  5, ...,  0,  0,  0],\n        [16,  4,  2, ...,  0,  0,  0],\n        [ 2,  5, 10, ...,  0,  0,  0],\n        ...,\n        [ 2,  5, 10, ...,  0,  0,  0],\n        [ 2,  5,  4, ...,  0,  0,  0],\n        [ 9,  5,  5, ...,  0,  0,  0]], dtype=int32),\n array([[ 756,  445, 1526, ...,    0,    0,    0],\n        [ 756,  445, 1526, ...,    0,    0,    0],\n        [ 662, 2547,  736, ...,    0,    0,    0],\n        ...,\n        [  90,  271,  131, ...,    0,    0,    0],\n        [ 662,  248,    4, ...,    0,    0,    0],\n        [ 662,  248,    4, ...,    0,    0,    0]], dtype=int32),\n array([[16,  7,  7, ...,  0,  0,  0],\n        [16,  7,  7, ...,  0,  0,  0],\n        [ 7,  5, 10, ...,  0,  0,  0],\n        ...,\n        [16,  7,  7, ...,  0,  0,  0],\n        [ 7,  5,  8, ...,  0,  0,  0],\n        [ 7,  5,  8, ...,  0,  0,  0]], dtype=int32),\n array([[0.91133817, 0.37864865, 0.13036962, ..., 0.17403315, 0.09116022,\n         0.29171271],\n        [0.97709295, 0.44629847, 0.12943879, ..., 0.        , 0.14864865,\n         0.34594595],\n        [0.67286071, 0.29003021, 0.28475749, ..., 0.25      , 0.        ,\n         0.        ],\n        ...,\n        [0.86922159, 0.37629938, 0.3470094 , ..., 0.        , 0.        ,\n         0.        ],\n        [0.83340471, 0.60150493, 0.40822863, ..., 0.        , 0.        ,\n         0.23163842],\n        [0.52690935, 0.1718267 , 0.07773821, ..., 0.23076923, 0.        ,\n         0.        ]]),\n array([[0.59565176, 0.41567585, 0.52881241, ..., 0.        , 0.        ,\n         0.14285714],\n        [0.58552084, 0.34926217, 0.57928386, ..., 0.2       , 0.        ,\n         0.        ],\n        [0.50944726, 0.17539573, 0.37273189, ..., 0.        , 0.25      ,\n         0.125     ],\n        ...,\n        [0.55991266, 0.28159961, 0.62540762, ..., 0.        , 0.        ,\n         0.        ],\n        [0.3304511 , 0.25813237, 0.5989047 , ..., 0.        , 0.        ,\n         0.        ],\n        [0.14789357, 0.08255306, 0.27940039, ..., 0.        , 0.42857143,\n         0.1       ]])]"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport tensorflow.keras.layers as layers\nfrom tensorflow import keras\nimport tensorflow.keras.backend as K\nfrom custom_layers.zeromasking import ZeroMaskedEntries\nfrom custom_layers.attention import Attention\nfrom custom_layers.multiheadattention_pe import MultiHeadAttention_PE\nfrom custom_layers.multiheadattention import MultiHeadAttention\n\n# Correlation Coefficient: Computes the Pearson correlation coefficient, while ignoring masked values.\n# Cosine Similarity: Measures the cosine of the angle between two non-zero vectors, effectively quantifying their similarity.\n\ndef correlation_coefficient(trait1, trait2):\n    x = trait1\n    y = trait2\n    \n    # maksing if either x or y is a masked value\n    mask_value = -0.\n    mask_x = K.cast(K.not_equal(x, mask_value), K.floatx())\n    mask_y = K.cast(K.not_equal(y, mask_value), K.floatx())\n    \n    mask = mask_x * mask_y\n    x_masked, y_masked = x * mask, y * mask\n    \n    mx = K.sum(x_masked) / K.sum(mask) # ignore the masked values when obtaining the mean\n    my = K.sum(y_masked) / K.sum(mask) # ignore the masked values when obtaining the mean\n    \n    xm, ym = (x_masked-mx) * mask, (y_masked-my) * mask # maksing the masked values\n    \n    r_num = K.sum(xm * ym)\n    r_den = K.sqrt(K.sum(K.square(xm)) * K.sum(K.square(ym)))\n    r = 0.\n    r = tf.cond(r_den > 0, lambda: r_num / (r_den), lambda: r+0)\n    return r\n\ndef cosine_sim(trait1, trait2):\n    x = trait1\n    y = trait2\n    \n    mask_value = 0.\n    mask_x = K.cast(K.not_equal(x, mask_value), K.floatx())\n    mask_y = K.cast(K.not_equal(y, mask_value), K.floatx())\n    \n    mask = mask_x * mask_y\n    x_masked, y_masked = x*mask, y*mask\n    \n    normalize_x = tf.nn.l2_normalize(x_masked,0) * mask # mask 값 반영     \n    normalize_y = tf.nn.l2_normalize(y_masked,0) * mask # mask 값 반영\n        \n    cos_similarity = tf.reduce_sum(tf.multiply(normalize_x, normalize_y))\n    return cos_similarity\n    \n\n# Trait Similarity Loss: This function calculates a similarity loss based on the correlation coefficient and cosine similarity \n# between different traits. It encourages the model to produce predictions that are similar for traits that have a high correlation.\n\n# Masked Loss Function: This function computes the mean squared error while ignoring certain masked values in \n# the target and predicted outputs.\n\n# Total Loss Function: Combines the masked loss and trait similarity loss, allowing for a balance between prediction \n# accuracy and trait similarity.\n\ndef trait_sim_loss(y_true, y_pred):\n    mask_value = -1\n    mask = K.cast(K.not_equal(y_true, mask_value), K.floatx())\n    \n    # masking\n    y_trans = tf.transpose(y_true * mask)\n    y_pred_trans = tf.transpose(y_pred * mask)\n    \n    sim_loss = 0.0\n    cnt = 0.0\n    ts_loss = 0.\n    #trait_num = y_true.shape[1]\n    trait_num = 9\n    print('trait num: ', trait_num)\n    \n    # start from idx 1, since we ignore the overall score \n    for i in range(1, trait_num):\n        for j in range(i+1, trait_num):\n            corr = correlation_coefficient(y_trans[i], y_trans[j])\n            sim_loss = tf.cond(corr>=0.7, lambda: tf.add(sim_loss, 1-cosine_sim(y_pred_trans[i], y_pred_trans[j])), \n                            lambda: tf.add(sim_loss, 0))\n            cnt = tf.cond(corr>=0.7, lambda: tf.add(cnt, 1), \n                            lambda: tf.add(cnt, 0))\n    ts_loss = tf.cond(cnt > 0, lambda: sim_loss/cnt, lambda: ts_loss+0)\n    return ts_loss\n    \ndef masked_loss_function(y_true, y_pred):\n    mask_value = -1\n    mask = K.cast(K.not_equal(y_true, mask_value), K.floatx())\n    mse = keras.losses.MeanSquaredError()\n    return mse(y_true * mask, y_pred * mask)\n\ndef total_loss(y_true, y_pred):\n    alpha = 0.7\n    mse_loss = masked_loss_function(y_true, y_pred)\n    ts_loss = trait_sim_loss(y_true, y_pred)\n    return alpha * mse_loss + (1-alpha) * ts_loss\n\ndef build_ProTACT(pos_vocab_size, vocab_size, maxnum, maxlen, readability_feature_count,\n                  linguistic_feature_count, configs, output_dim, num_heads, embedding_weights):\n    embedding_dim = configs.EMBEDDING_DIM\n    dropout_prob = configs.DROPOUT\n    cnn_filters = configs.CNN_FILTERS\n    cnn_kernel_size = configs.CNN_KERNEL_SIZE\n    lstm_units = configs.LSTM_UNITS\n    \n    ### 1. Essay Representation\n    \n    # Input layer for position information of words in the essay\n    pos_input = layers.Input(shape=(maxnum * maxlen,), dtype='int32', name='pos_input')\n    \n    # Embedding layer for position encoding, transforming indices into dense vectors\n    pos_x = layers.Embedding(output_dim=embedding_dim, input_dim=pos_vocab_size, input_length=maxnum * maxlen,\n                             weights=None, mask_zero=True, name='pos_x')(pos_input)\n    \n    # Masking out the padding in the embeddings\n    pos_x_maskedout = ZeroMaskedEntries(name='pos_x_maskedout')(pos_x)\n    \n    # Applying dropout to the position embeddings to prevent overfitting\n    pos_drop_x = layers.Dropout(dropout_prob, name='pos_drop_x')(pos_x_maskedout)\n    \n    # Reshaping the embeddings for CNN processing\n    pos_resh_W = layers.Reshape((maxnum, maxlen, embedding_dim), name='pos_resh_W')(pos_drop_x)\n    \n    # Convolutional layer to extract local features from position embeddings\n    pos_zcnn = layers.TimeDistributed(layers.Conv1D(cnn_filters, cnn_kernel_size, padding='valid'), name='pos_zcnn')(pos_resh_W)\n    \n    # Applying attention to summarize the feature maps generated by the CNN\n    pos_avg_zcnn = layers.TimeDistributed(Attention(), name='pos_avg_zcnn')(pos_zcnn)\n\n    # Input layer for linguistic features\n    linguistic_input = layers.Input((linguistic_feature_count,), name='linguistic_input')\n    # Input layer for readability features\n    readability_input = layers.Input((readability_feature_count,), name='readability_input')\n\n    # Applying Multi-Head Attention to position embeddings\n    pos_MA_list = [MultiHeadAttention(100, num_heads)(pos_avg_zcnn) for _ in range(output_dim)]\n    # LSTM layers to capture sequential dependencies in attention outputs\n    pos_MA_lstm_list = [layers.LSTM(lstm_units, return_sequences=True)(pos_MA) for pos_MA in pos_MA_list]\n    # Attention mechanism to summarize LSTM outputs\n    pos_avg_MA_lstm_list = [Attention()(pos_hz_lstm) for pos_hz_lstm in pos_MA_lstm_list]\n\n    ### 2. Prompt Representation\n    # word embedding\n\n    # Input layer for word indices in the prompt\n    prompt_word_input = layers.Input(shape=(maxnum * maxlen,), dtype='int32', name='prompt_word_input')\n    # Word embedding for the prompt, using pre-trained weights\n    prompt = layers.Embedding(output_dim=embedding_dim, input_dim=vocab_size, input_length=maxnum * maxlen,\n                              weights=embedding_weights, mask_zero=True, name='prompt')(prompt_word_input)\n    # Masking out the padding in the prompt embeddings\n    prompt_maskedout = ZeroMaskedEntries(name='prompt_maskedout')(prompt)\n\n    # pos embedding\n    # Input layer for position indices in the prompt\n    prompt_pos_input = layers.Input(shape=(maxnum * maxlen,), dtype='int32', name='prompt_pos_input')\n    # Position embedding for the prompt\n    prompt_pos = layers.Embedding(output_dim=embedding_dim, input_dim=pos_vocab_size, input_length=maxnum * maxlen,\n                                  weights=None, mask_zero=True, name='pos_prompt')(prompt_pos_input)\n    # Masking out the padding in the position embeddings of the prompt\n    prompt_pos_maskedout = ZeroMaskedEntries(name='prompt_pos_maskedout')(prompt_pos)\n    \n    # add word + pos embedding\n    prompt_emb = tf.keras.layers.Add()([prompt_maskedout, prompt_pos_maskedout])\n\n    # Applying dropout to the combined embeddings\n    prompt_drop_x = layers.Dropout(dropout_prob, name='prompt_drop_x')(prompt_emb)\n    # Reshaping for CNN processing\n    prompt_resh_W = layers.Reshape((maxnum, maxlen, embedding_dim), name='prompt_resh_W')(prompt_drop_x)\n    # Convolutional layer to extract features from the prompt\n    prompt_zcnn = layers.TimeDistributed(layers.Conv1D(cnn_filters, cnn_kernel_size, padding='valid'), name='prompt_zcnn')(prompt_resh_W)\n    # Applying attention to summarize the prompt feature maps\n    prompt_avg_zcnn = layers.TimeDistributed(Attention(), name='prompt_avg_zcnn')(prompt_zcnn)\n\n    # Applying Multi-Head Attention to prompt embeddings\n    prompt_MA_list = MultiHeadAttention(100, num_heads)(prompt_avg_zcnn)\n    # LSTM to capture sequential dependencies in the prompt attention outputs\n    prompt_MA_lstm_list = layers.LSTM(lstm_units, return_sequences=True)(prompt_MA_list)\n    # Attention to summarize the outputs from the LSTM\n    prompt_avg_MA_lstm_list = Attention()(prompt_MA_lstm_list)\n\n    # Query\n    query = prompt_avg_MA_lstm_list\n\n    # Attention between position and prompt representations\n    es_pr_MA_list = [MultiHeadAttention_PE(100, num_heads)(pos_avg_MA_lstm_list[i], query) for i in range(output_dim)]\n    # LSTM layers to process the results from attention\n    es_pr_MA_lstm_list = [layers.LSTM(lstm_units, return_sequences=True)(pos_hz_MA) for pos_hz_MA in es_pr_MA_list]\n    # Summarizing the LSTM outputs with attention\n    es_pr_avg_lstm_list = [Attention()(pos_hz_lstm) for pos_hz_lstm in es_pr_MA_lstm_list]\n    # Concatenating representations with linguistic and readability features\n    es_pr_feat_concat = [layers.Concatenate()([rep, linguistic_input, readability_input])\n                         for rep in es_pr_avg_lstm_list]\n\n    # Wrapping tf.concat inside a Lambda layer to handle concatenation\n    pos_avg_hz_lstm = layers.Lambda(lambda reps: tf.concat(\n        [layers.Reshape((1, lstm_units + linguistic_feature_count + readability_feature_count))(rep)\n         for rep in reps], axis=-2))(es_pr_feat_concat)\n\n    final_preds = []\n    for index, _ in enumerate(range(output_dim)):\n        mask = np.array([True for _ in range(output_dim)])\n        mask[index] = False\n        \n        # Wrapping tf.boolean_mask inside a Lambda layer\n        non_target_rep = layers.Lambda(lambda x: tf.boolean_mask(x, mask, axis=-2))(pos_avg_hz_lstm)\n        target_rep = pos_avg_hz_lstm[:, index:index+1]\n        \n        # Applying attention to the target representation and the non-target representations\n        att_attention = layers.Attention()([target_rep, non_target_rep])\n        # Concatenating the target and attended representations\n        attention_concat = layers.Concatenate(axis=-1)([target_rep, att_attention])\n        attention_concat = layers.Flatten()(attention_concat)\n        # Final prediction layer\n        final_pred = layers.Dense(units=1, activation='sigmoid')(attention_concat)\n        final_preds.append(final_pred)\n\n    # Concatenating all final predictions\n    y = layers.Concatenate()([pred for pred in final_preds])\n\n    model = keras.Model(inputs=[pos_input, prompt_word_input, prompt_pos_input, linguistic_input, readability_input], outputs=y)\n    model.summary()\n    model.compile(loss=total_loss, optimizer='rmsprop')\n\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T06:34:12.953885Z","iopub.execute_input":"2024-11-01T06:34:12.954687Z","iopub.status.idle":"2024-11-01T06:34:13.004797Z","shell.execute_reply.started":"2024-11-01T06:34:12.954640Z","shell.execute_reply":"2024-11-01T06:34:13.003609Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"The `build_ProTACT` function defines a neural network model for text analysis, likely focused on essay assessment or a similar task. Here’s a detailed explanation of each formal parameter in the function signature:\n\n### Function Signature\n\n```python\ndef build_ProTACT(pos_vocab_size, vocab_size, maxnum, maxlen, readability_feature_count,\n                  linguistic_feature_count, configs, output_dim, num_heads, embedding_weights):\n```\n\n### Parameter Descriptions\n\n1. **`pos_vocab_size`**:\n   - **Type**: `int`\n   - **Description**: The size of the vocabulary used for position embeddings. This refers to the number of unique position indices in the input data. It is essential for the embedding layer that transforms these indices into dense vector representations.\n\n2. **`vocab_size`**:\n   - **Type**: `int`\n   - **Description**: The size of the word vocabulary. This indicates the total number of unique words or tokens in the dataset. It is crucial for the embedding layer that handles word embeddings.\n\n3. **`maxnum`**:\n   - **Type**: `int`\n   - **Description**: The maximum number of segments (or sentences) per input example. This parameter determines how many sentences the model will consider for each essay or document.\n\n4. **`maxlen`**:\n   - **Type**: `int`\n   - **Description**: The maximum length of each segment (or sentence) in terms of the number of words. It specifies how many words will be included from each sentence during training.\n\n5. **`readability_feature_count`**:\n   - **Type**: `int`\n   - **Description**: The number of features related to the readability of the text. These could include various readability metrics that quantify how easy or difficult the text is to read.\n\n6. **`linguistic_feature_count`**:\n   - **Type**: `int`\n   - **Description**: The number of linguistic features derived from the text. These features could represent syntactic, semantic, or stylistic aspects of the essays that might help improve the model's performance.\n\n7. **`configs`**:\n   - **Type**: `object` (or `dict`)\n   - **Description**: A configuration object or dictionary that contains various hyperparameters for the model. This can include settings for embedding dimensions, dropout rates, CNN filters, kernel sizes, and LSTM units, which dictate how the model processes the input data.\n\n8. **`output_dim`**:\n   - **Type**: `int`\n   - **Description**: The number of output dimensions or traits that the model will predict. This is critical as it defines the shape of the model's output layer and represents the different traits associated with the essays.\n\n9. **`num_heads`**:\n   - **Type**: `int`\n   - **Description**: The number of attention heads used in the multi-head attention mechanism. Using multiple heads allows the model to attend to different parts of the input simultaneously, capturing various relationships and interactions more effectively.\n\n10. **`embedding_weights`**:\n    - **Type**: `ndarray` (e.g., `numpy` array)\n    - **Description**: A pre-trained embedding matrix (such as GloVe or Word2Vec) that initializes the word embedding layer. This matrix provides dense vector representations for the words in the vocabulary, which can enhance the model’s performance by leveraging learned semantic relationships.\n\n### Summary\nEach of these parameters plays a crucial role in defining the architecture and functionality of the ProTACT model. By customizing these inputs, you can tailor the model to effectively analyze and predict traits based on the essays provided. ","metadata":{}},{"cell_type":"code","source":"model = build_ProTACT(len(pos_vocab), len(word_vocab), max_sentnum, max_sentlen, \n                      X_train_readability.shape[1],\n                      X_train_linguistic_features.shape[1],\n                      configs, Y_train.shape[1], num_heads, embed_table)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T06:34:13.311395Z","iopub.execute_input":"2024-11-01T06:34:13.311858Z","iopub.status.idle":"2024-11-01T06:34:17.051718Z","shell.execute_reply.started":"2024-11-01T06:34:13.311815Z","shell.execute_reply":"2024-11-01T06:34:17.050652Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ prompt_word_input   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4850\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_pos_input    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4850\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_input           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4850\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt (\u001b[38;5;33mEmbedding\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4850\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │    \u001b[38;5;34m200,000\u001b[0m │ prompt_word_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4850\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ prompt_word_inpu… │\n│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_prompt          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4850\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │      \u001b[38;5;34m1,750\u001b[0m │ prompt_pos_input… │\n│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4850\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ prompt_pos_input… │\n│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_x (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4850\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │      \u001b[38;5;34m1,750\u001b[0m │ pos_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4850\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ pos_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_maskedout    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4850\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ prompt[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n│ (\u001b[38;5;33mZeroMaskedEntries\u001b[0m) │                   │            │ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_pos_maskedo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4850\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ pos_prompt[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│ (\u001b[38;5;33mZeroMaskedEntries\u001b[0m) │                   │            │ not_equal_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_x_maskedout     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4850\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ pos_x[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n│ (\u001b[38;5;33mZeroMaskedEntries\u001b[0m) │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4850\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ prompt_maskedout… │\n│                     │                   │            │ prompt_pos_maske… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_drop_x          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4850\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ pos_x_maskedout[\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_drop_x       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4850\u001b[0m, \u001b[38;5;34m50\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_resh_W          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m97\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ pos_drop_x[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│ (\u001b[38;5;33mReshape\u001b[0m)           │ \u001b[38;5;34m50\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_resh_W       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m97\u001b[0m, \u001b[38;5;34m50\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ prompt_drop_x[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mReshape\u001b[0m)           │ \u001b[38;5;34m50\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_zcnn            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m97\u001b[0m, \u001b[38;5;34m46\u001b[0m,    │     \u001b[38;5;34m25,100\u001b[0m │ pos_resh_W[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ \u001b[38;5;34m100\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_zcnn         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m97\u001b[0m, \u001b[38;5;34m46\u001b[0m,    │     \u001b[38;5;34m25,100\u001b[0m │ prompt_resh_W[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ \u001b[38;5;34m100\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_avg_zcnn        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m97\u001b[0m, \u001b[38;5;34m100\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ pos_zcnn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_avg_zcnn     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m97\u001b[0m, \u001b[38;5;34m100\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ prompt_zcnn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m40,400\u001b[0m │ pos_avg_zcnn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m40,400\u001b[0m │ prompt_avg_zcnn[\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m40,400\u001b[0m │ pos_avg_zcnn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m40,400\u001b[0m │ pos_avg_zcnn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m40,400\u001b[0m │ pos_avg_zcnn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m40,400\u001b[0m │ pos_avg_zcnn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m40,400\u001b[0m │ pos_avg_zcnn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m40,400\u001b[0m │ pos_avg_zcnn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m40,400\u001b[0m │ pos_avg_zcnn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m40,400\u001b[0m │ pos_avg_zcnn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_11        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lstm_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_6         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_7         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_8         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lstm_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_9         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lstm_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m40,400\u001b[0m │ attention_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m40,400\u001b[0m │ attention_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m40,400\u001b[0m │ attention_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m40,400\u001b[0m │ attention_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m40,400\u001b[0m │ attention_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m40,400\u001b[0m │ attention_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m40,400\u001b[0m │ attention_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m40,400\u001b[0m │ attention_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m40,400\u001b[0m │ attention_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_11 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_12 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_13 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_14 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_15 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_16 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_17 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_18 (\u001b[38;5;33mLSTM\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m) │     \u001b[38;5;34m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_12        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lstm_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ linguistic_input    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ readability_input   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_13        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lstm_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_14        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lstm_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_15        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lstm_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_16        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lstm_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_17        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lstm_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_18        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lstm_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_19        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lstm_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_20        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ lstm_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m187\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ attention_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m187\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ attention_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m187\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ attention_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m187\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ attention_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m187\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ attention_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m187\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ attention_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m187\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ attention_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m187\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ attention_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m187\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ attention_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m187\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│                     │                   │            │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ concatenate_3[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ concatenate_4[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ concatenate_5[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ concatenate_6[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ concatenate_7[\u001b[38;5;34m0\u001b[0m]… │\n│                     │                   │            │ concatenate_8[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item (\u001b[38;5;33mGetItem\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m187\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m187\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m187\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m187\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m187\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_3 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m187\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_3          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m187\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_4 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m187\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_4          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m187\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_5 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m187\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_5          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m187\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_6 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m187\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_6          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m187\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_7 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m187\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_7          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m187\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_8 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m187\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_8          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m187\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_9 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m187\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_21        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m187\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ lambda_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_22        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m187\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ get_item_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ lambda_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_23        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m187\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ get_item_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ lambda_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_24        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m187\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ get_item_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ lambda_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_25        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m187\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ get_item_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ lambda_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_26        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m187\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ get_item_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ lambda_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_27        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m187\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ get_item_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ lambda_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_28        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m187\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ get_item_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ lambda_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_29        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m187\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ get_item_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ lambda_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_9       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m374\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ attention_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m374\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ get_item_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ attention_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_11      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m374\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ get_item_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ attention_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_12      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m374\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ get_item_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ attention_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_13      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m374\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ get_item_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ attention_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_14      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m374\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ get_item_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ attention_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_15      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m374\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ get_item_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ attention_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_16      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m374\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ get_item_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ attention_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_17      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m374\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ get_item_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ attention_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m374\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_9[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m374\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_10[\u001b[38;5;34m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m374\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_11[\u001b[38;5;34m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m374\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_12[\u001b[38;5;34m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m374\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_13[\u001b[38;5;34m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m374\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_14[\u001b[38;5;34m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m374\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_15[\u001b[38;5;34m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m374\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_16[\u001b[38;5;34m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_8 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m374\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate_17[\u001b[38;5;34m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_76 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m375\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_77 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m375\u001b[0m │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_78 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m375\u001b[0m │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_79 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m375\u001b[0m │ flatten_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_80 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m375\u001b[0m │ flatten_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_81 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m375\u001b[0m │ flatten_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_82 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m375\u001b[0m │ flatten_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_83 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m375\u001b[0m │ flatten_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_84 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m375\u001b[0m │ flatten_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_18      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ dense_76[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_77[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│                     │                   │            │ dense_78[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│                     │                   │            │ dense_79[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│                     │                   │            │ dense_80[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│                     │                   │            │ dense_81[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│                     │                   │            │ dense_82[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│                     │                   │            │ dense_83[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│                     │                   │            │ dense_84[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ prompt_word_input   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4850</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_pos_input    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4850</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_input           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4850</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4850</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">200,000</span> │ prompt_word_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4850</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ prompt_word_inpu… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_prompt          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4850</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,750</span> │ prompt_pos_input… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4850</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ prompt_pos_input… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_x (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4850</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,750</span> │ pos_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4850</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ pos_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_maskedout    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4850</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ prompt[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroMaskedEntries</span>) │                   │            │ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_pos_maskedo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4850</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ pos_prompt[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroMaskedEntries</span>) │                   │            │ not_equal_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_x_maskedout     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4850</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ pos_x[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroMaskedEntries</span>) │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4850</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ prompt_maskedout… │\n│                     │                   │            │ prompt_pos_maske… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_drop_x          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4850</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ pos_x_maskedout[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_drop_x       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4850</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_resh_W          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ pos_drop_x[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_resh_W       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ prompt_drop_x[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_zcnn            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">25,100</span> │ pos_resh_W[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_zcnn         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">25,100</span> │ prompt_resh_W[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_avg_zcnn        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ pos_zcnn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_avg_zcnn     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ prompt_zcnn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">40,400</span> │ pos_avg_zcnn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">40,400</span> │ prompt_avg_zcnn[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">40,400</span> │ pos_avg_zcnn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">40,400</span> │ pos_avg_zcnn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">40,400</span> │ pos_avg_zcnn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">40,400</span> │ pos_avg_zcnn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">40,400</span> │ pos_avg_zcnn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">40,400</span> │ pos_avg_zcnn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">40,400</span> │ pos_avg_zcnn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">40,400</span> │ pos_avg_zcnn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_11        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_6         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_7         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_8         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_9         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">40,400</span> │ attention_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ attention_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">40,400</span> │ attention_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ attention_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">40,400</span> │ attention_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ attention_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">40,400</span> │ attention_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ attention_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">40,400</span> │ attention_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ attention_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">40,400</span> │ attention_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ attention_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">40,400</span> │ attention_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ attention_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">40,400</span> │ attention_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ attention_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">40,400</span> │ attention_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ attention_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_12        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ linguistic_input    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ readability_input   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_13        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_14        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_15        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_16        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_17        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_18        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_19        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_20        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                     │                   │            │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ concatenate_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ concatenate_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ concatenate_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │                   │            │ concatenate_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_3          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_4          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_5          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_6          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_7          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_8          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_21        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ lambda_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_22        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ lambda_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_23        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ lambda_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_24        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ lambda_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_25        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ lambda_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_26        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ lambda_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_27        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ lambda_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_28        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ lambda_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_29        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">187</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ lambda_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_9       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">374</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">374</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_11      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">374</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_12      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">374</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_13      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">374</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_14      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">374</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_15      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">374</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_16      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">374</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_17      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">374</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ attention_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">374</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">374</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">374</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">374</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">374</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">374</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">374</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">374</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">374</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_76 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_77 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span> │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_78 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span> │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_79 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span> │ flatten_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span> │ flatten_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span> │ flatten_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span> │ flatten_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span> │ flatten_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">375</span> │ flatten_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_18      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_76[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_77[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│                     │                   │            │ dense_78[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│                     │                   │            │ dense_79[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│                     │                   │            │ dense_80[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│                     │                   │            │ dense_81[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│                     │                   │            │ dense_82[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│                     │                   │            │ dense_83[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│                     │                   │            │ dense_84[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,552,275\u001b[0m (9.74 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,552,275</span> (9.74 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,552,275\u001b[0m (9.74 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,552,275</span> (9.74 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"markdown","source":"It looks like you've successfully instantiated the ProTACT model using the `build_ProTACT` function and are viewing its architecture summary from Keras. Let’s break down what you're seeing in the model summary and address the warning you received.\n\n### Model Summary Breakdown\n\n1. **Input Layers**:\n   - **`prompt_word_input`, `prompt_pos_input`, `pos_input`**: \n     - **Shape**: `(None, 4850)` \n     - **Description**: These are the input layers for the word indices of the prompt, position indices of the prompt, and position indices of the essays, respectively. The `None` indicates that the model can accept a variable batch size, while `4850` is the total number of words or tokens expected in each input example.\n\n2. **Embedding Layers**:\n   - **`prompt (Embedding)`**:\n     - **Output Shape**: `(None, 4850, 50)`\n     - **Parameters**: `200,000`\n     - **Description**: This layer transforms the prompt word indices into dense vector representations (embeddings) of size `50`. The total parameters indicate that there are 200,000 trainable weights in this embedding layer.\n   \n   - **`pos_prompt (Embedding)` and `pos_x (Embedding)`**:\n     - **Output Shape**: `(None, 4850, 50)`\n     - **Parameters**: `1,750` each\n     - **Description**: These layers transform position indices into dense vectors, also of size `50`. The low number of parameters suggests that these embeddings are initialized with a smaller vocabulary.\n\n3. **Zero Masked Entries**:\n   - **`prompt_maskedout`, `prompt_pos_maskedout`, `pos_x_maskedout`**:\n     - **Output Shape**: `(None, 4850, 50)`\n     - **Description**: These custom layers (likely defined in your `ZeroMaskedEntries` class) remove or mask out the padded (zero) entries from the embeddings to focus only on the actual words. They effectively prepare the embeddings for subsequent layers by ensuring that padding does not affect the calculations.\n\nLet's break down the additional layers from your model summary and explain what each of them does.\n\n1. **Add Layer**:\n   - **`add (Add)`**:\n     - **Output Shape**: `(None, 4850, 50)`\n     - **Description**: This layer performs an element-wise addition of two tensors (likely the masked outputs of the prompt and position embeddings). The resulting tensor retains the same shape as the input tensors, which is useful for combining different information streams.\n\n2. **Dropout Layers**:\n   - **`pos_drop_x (Dropout)`** and **`prompt_drop_x (Dropout)`**:\n     - **Output Shape**: `(None, 4850, 50)`\n     - **Description**: These layers apply dropout to the previous outputs (from the `add` layer and masked outputs, respectively). Dropout helps prevent overfitting by randomly setting a fraction of input units to zero during training, which forces the model to learn more robust features.\n\n3. **Reshape Layers**:\n   - **`pos_resh_W (Reshape)`** and **`prompt_resh_W (Reshape)`**:\n     - **Output Shape**: `(None, 97, 50, 50)`\n     - **Description**: These layers reshape the tensors from the previous dropout layers. The specifics of the shape will depend on your model's design. The `97` could represent a certain number of sentences or time steps, while the `50` represents the embedding size. Reshaping is often done to prepare the data for subsequent layers that expect inputs of specific dimensions.\n\n4. **TimeDistributed Layers**:\n   - **`pos_zcnn (TimeDistributed)`** and **`prompt_zcnn (TimeDistributed)`**:\n     - **Output Shape**: `(None, 97, 46, 100)`\n     - **Parameters**: `25,100` each\n     - **Description**: These layers apply a convolutional neural network (CNN) operation to each time step independently. The output shape indicates that the output feature maps have a width of `46` and a depth of `100`. The `TimeDistributed` wrapper allows CNN layers to process each time step in the input sequences separately.\n\n5. **Average Pooling Layers**:\n   - **`pos_avg_zcnn (TimeDistributed)`** and **`prompt_avg_zcnn (TimeDistributed)`**:\n     - **Output Shape**: `(None, 97, 100)`\n     - **Description**: These layers perform average pooling over the convolutional outputs. This helps reduce dimensionality while retaining the most important features. The pooling operation typically takes the average across the spatial dimensions, reducing the width and height while keeping the depth.\n\n6. **Multi-Head Attention Layers**:\n   - **`multi_head_attention...`** (multiple layers):\n     - **Output Shape**: `(None, None, 100)`\n     - **Parameters**: `40,400` each\n     - **Description**: These layers implement multi-head attention mechanisms. Each head in multi-head attention learns different attention distributions and captures various features of the input. The output shape suggests that the attention layers produce feature representations with a depth of `100`. The `None` in the shape indicates that the model can handle variable lengths of input sequences. Multiple heads allow the model to focus on different parts of the input simultaneously, improving its capacity to capture complex patterns.\n\n### Summary of Architecture Flow\nThe model architecture you've provided outlines a multi-layered neural network that combines various components to process input text and potentially produce embeddings or classifications:\n\n1. The input layers accept tokenized word indices for both prompts and positions.\n2. Embedding layers convert these indices into dense representations.\n3. Masked entries help to focus the model on valid inputs, avoiding the influence of padding.\n4. Dropout layers mitigate overfitting by randomly deactivating units during training.\n5. Reshape layers prepare the data for convolutional operations.\n6. CNN layers capture local features from the sequences, which are then pooled for dimensionality reduction.\n7. Finally, multi-head attention layers help the model learn relationships and dependencies between different parts of the input sequences.\n\nLet’s continue analyzing the layers from your model summary, focusing on the multiple instances of the Multi-Head Attention and LSTM layers.\n\n### Model Layers Breakdown (Continued)\n\n7. **Multi-Head Attention Layers**:\n   - **`multi_head_attenti… (MultiHeadAttention)`**:\n     - **Output Shape**: `(None, None, 100)`\n     - **Parameters**: `40,400` each\n     - **Description**: The model has several instances of the Multi-Head Attention layer. Each one processes its input independently to produce an output representation. The `None` dimension indicates that the output can accommodate variable-length sequences. The `100` denotes the size of the output embeddings. This design allows the model to attend to different parts of the input sequences, capturing various dependencies and relationships.\n\n### LSTM Layers\n8. **LSTM Layers**:\n   - **`lstm (LSTM)`**, **`lstm_9 (LSTM)`**, **`lstm_1 (LSTM)`**, **`lstm_2 (LSTM)`**, **`lstm_3 (LSTM)`**, **`lstm_4 (LSTM)`**, **`lstm_5 (LSTM)`**, **`lstm_6 (LSTM)`**, **`lstm_7 (LSTM)`**, **`lstm_8 (LSTM)`**:\n     - **Output Shape**: `(None, None, 100)`\n     - **Parameters**: `80,400` each\n     - **Description**: There are multiple LSTM layers in this model. Each LSTM layer processes the outputs from the previous Multi-Head Attention layers. They maintain sequential information and capture long-range dependencies in the data. The output shape reflects that these layers can handle variable-length sequences, maintaining an output size of `100`, which likely corresponds to the dimensionality of the representations produced by the attention layers.\n\n### Summary of Model Flow\nHere’s a brief overview of how these layers interact:\n\n1. **Multi-Head Attention**: The multiple attention layers learn to focus on different parts of the input sequences. Each layer can attend to the context from different sequences and extract various features.\n\n2. **LSTM Processing**: Following the attention mechanisms, the LSTM layers process the output to capture sequential dependencies. LSTMs are particularly useful in sequence modeling tasks because they can remember information from earlier time steps, which is vital for understanding context in text.\n\n### Implications for Your Model\n- **Complex Interactions**: By stacking multiple attention and LSTM layers, your model can learn complex interactions between words and their contexts across sequences.\n- **Overfitting and Generalization**: With so many layers, it's essential to monitor for overfitting. Consider using techniques like dropout (which you already have) and regularization to help with generalization.\n- **Hyperparameter Tuning**: The number of layers, attention heads, and LSTM units are all hyperparameters that could significantly affect performance. It may be beneficial to experiment with different configurations based on your task requirements.\n\nLet's continue breaking down the model layers you provided, focusing on the attention and LSTM layers that follow.\n\n### Attention Layers\n1. **Attention Layers**:\n   - **`attention_1` to `attention_9`**:\n     - **Output Shape**: `(None, 100)`\n     - **Parameters**: `0`\n     - **Description**: Each of these attention layers produces a fixed-size output of `100`. They take the output from the corresponding LSTM layers (e.g., `lstm`, `lstm_9`, etc.) as inputs. The attention mechanism allows the model to focus on specific parts of the sequence, enhancing the representation by weighting the importance of different input tokens based on the context provided by the LSTM.\n\n### Multi-Head Attention Layers\n2. **Multi-Head Attention Layers**:\n   - **`multi_head_attenti… (MultiHeadAttention)`** (multiple instances):\n     - **Output Shape**: `(None, None, 100)`\n     - **Parameters**: `40,400` each\n     - **Description**: These layers are designed to combine information from the various attention outputs (`attention_1` to `attention_9`). They allow the model to jointly attend to different features across multiple attention outputs, preserving the sequence information. The output shape indicates that they produce variable-length sequences (due to `None`) while maintaining a dimensionality of `100`.\n\n### LSTM Layers\n3. **LSTM Layers**:\n   - **`lstm_10 (LSTM)`** to **`lstm_18 (LSTM)`**:\n     - **Output Shape**: `(None, None, 100)`\n     - **Parameters**: `80,400` each\n     - **Description**: These layers follow the multi-head attention layers and continue processing the output sequences. Similar to the previous LSTM layers, they help to maintain temporal dependencies and manage long-range contexts in the data, effectively making the model capable of understanding sequences over time.\n\n### Summary of Model Flow\nThe structure of your model is quite intricate, with a series of attention mechanisms followed by LSTM layers. Here’s a simplified flow of how data moves through the model:\n\n1. **Initial LSTM Layers**: These layers process the input sequences to extract features and maintain sequential information.\n   \n2. **Attention Layers**: Each LSTM output is passed through corresponding attention layers, which weigh the importance of various parts of the sequence. The outputs of these layers are fixed in size (100).\n\n3. **Multi-Head Attention**: The attention outputs are further processed by multi-head attention layers that combine information from multiple attention heads. This allows the model to integrate diverse perspectives from the sequence data.\n\n4. **Final LSTM Layers**: The processed sequences from the multi-head attention layers are then fed into additional LSTM layers to refine the representation and maintain temporal dependencies.\n\n\nIt looks like you're working with a complex model architecture in Keras. From the details you've shared, it appears to be an LSTM-based neural network with multiple attention layers, combining various inputs, likely for a task like sequence modeling or natural language processing. Here’s a brief overview of the components you're working with:\n\n1. **Input Layers**: \n   - `linguistic_input`: Accepts input sequences of length 52.\n   - `readability_input`: Accepts input sequences of length 35.\n\n2. **LSTM Layers**: \n   - Several LSTM layers (e.g., `lstm_10`, `lstm_11`, etc.) are present, processing the sequences with attention mechanisms applied on their outputs.\n\n3. **Attention Mechanisms**:\n   - Attention layers (e.g., `attention_12`, `attention_13`, etc.) are connected to the LSTM outputs. This indicates that the model is designed to focus on different parts of the input sequences when making predictions.\n\n4. **Concatenation Layers**:\n   - Multiple concatenation layers (e.g., `concatenate`, `concatenate_1`, etc.) are merging outputs from the attention layers with other inputs, resulting in larger feature vectors.\n\n5. **Lambda Layers**: \n   - Several lambda layers are employed to manipulate the data shapes or select specific dimensions, facilitating the model's workflow.\n\n6. **Output Preparation**:\n   - The final layers, which appear to concatenate the attention outputs with corresponding input sequences, indicate that the model is preparing to make predictions or output a structured representation based on the combined features.\n\n### Considerations\n- **Batch Size**: The `(None, ...)` dimension in the input shape indicates that the model can handle variable batch sizes, which is standard in Keras.\n- **Dimensionality**: The final concatenation layers output vectors of shape `(None, 1, 374)`, which suggests that the model might be designed to output a single sequence prediction based on a combination of input and attended features.\n \n \nThe model summary you've provided indicates that you have a fairly complex architecture involving multiple Flatten layers, followed by Dense layers and a Concatenate layer. Here’s a breakdown of what you’re looking at:\n\n1. **Flatten Layers**: You have eight `Flatten` layers, each converting the output of their respective preceding layers into a one-dimensional tensor of shape `(None, 374)`. This is typical when you want to transition from convolutional or recurrent layers to fully connected (Dense) layers.\n\n2. **Dense Layers**: Each `Flatten` layer is followed by a `Dense` layer that produces a single output (shape `(None, 1)`), suggesting that this model is likely performing a regression task or binary classification (predicting a single value).\n\n3. **Concatenate Layer**: Finally, there’s a `Concatenate` layer that takes the outputs from all eight `Dense` layers, merging them into a single tensor of shape `(None, 9)`. This could be useful for tasks that require combining predictions from multiple inputs or branches of the model.\n\n4. **Total Parameters**: The model has a total of **2,552,275** parameters, all of which are trainable. This suggests a significant amount of complexity, which might lead to overfitting if the dataset is not large enough.\n\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}