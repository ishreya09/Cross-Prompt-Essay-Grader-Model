import tensorflow.keras.backend as K
from tensorflow.keras.layers import Layer

# The ZeroMaskedEntries layer is particularly useful in models that process sequences, 
# like those found in natural language processing tasks. It helps in dealing with 
# padded sequences by ensuring that the model ignores the embeddings of padding 
# tokens during training and inference. By zeroing out these masked entries, the 
# layer enables the model to focus only on relevant parts of the input data.
class ZeroMaskedEntries(Layer):
    """
    This layer is called after an Embedding layer.
    It zeros out all of the masked-out embeddings.
    It also swallows the mask without passing it on.
    You can change this to default pass-on behavior as follows:

    def compute_mask(self, x, mask=None):
        if not self.mask_zero:
            return None
        else:
            return K.not_equal(x, 0)
    """

    def __init__(self, **kwargs):
        self.support_mask = True
        super(ZeroMaskedEntries, self).__init__(**kwargs)

    def build(self, input_shape):
        self.output_dim = input_shape[1]
        self.repeat_dim = input_shape[2]

    def call(self, x, mask=None):
        mask = K.cast(mask, 'float32')
        mask = K.repeat(mask, self.repeat_dim)
        mask = K.permute_dimensions(mask, (0, 2, 1))
        return x * mask

    def compute_mask(self, input_shape, input_mask=None):
        return None
