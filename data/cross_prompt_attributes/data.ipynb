{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data combined and saved to 'combined_data.csv' without duplicates.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Base directory containing the subdirectories\n",
    "# base_dir = 'data/cross_prompt_attributes'\n",
    "base_dir=''\n",
    "combined_data = []\n",
    "\n",
    "# Loop through each numbered folder (1 to 8)\n",
    "for i in range(1, 9):\n",
    "    folder_path = os.path.join(base_dir, str(i))\n",
    "    \n",
    "    # List of file names to read from each subdirectory\n",
    "    file_names = ['train.pk', 'dev.pk', 'test.pk']\n",
    "    \n",
    "    # Load and append data from each file in the folder\n",
    "    for file_name in file_names:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Check if the file exists to avoid errors\n",
    "        if os.path.isfile(file_path):\n",
    "            with open(file_path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                \n",
    "                # Assuming each loaded file contains a list of dictionaries\n",
    "                combined_data.extend(data)\n",
    "\n",
    "# Convert to DataFrame, remove duplicates, and save as CSV\n",
    "df = pd.DataFrame(combined_data)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('combined_data.csv', index=False)\n",
    "print(\"Data combined and saved to 'combined_data.csv' without duplicates.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data combined, sorted by 'prompt_id', and saved to 'combined_data.csv' without duplicates.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Base directory containing the subdirectories\n",
    "base_dir = ''\n",
    "combined_data = []\n",
    "\n",
    "# Loop through each numbered folder (1 to 8)\n",
    "for i in range(1, 9):\n",
    "    folder_path = os.path.join(base_dir, str(i))\n",
    "    \n",
    "    # List of file names to read from each subdirectory\n",
    "    file_names = ['train.pk', 'dev.pk', 'test.pk']\n",
    "    \n",
    "    # Load and append data from each file in the folder\n",
    "    for file_name in file_names:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Check if the file exists to avoid errors\n",
    "        if os.path.isfile(file_path):\n",
    "            with open(file_path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                \n",
    "                # Assuming each loaded file contains a list of dictionaries\n",
    "                combined_data.extend(data)\n",
    "\n",
    "# Convert to DataFrame, remove duplicates, and sort by prompt_id\n",
    "df = pd.DataFrame(combined_data)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Sort DataFrame by prompt_id\n",
    "df.sort_values(by='prompt_id', inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('combined_data.csv', index=False)\n",
    "print(\"Data combined, sorted by 'prompt_id', and saved to 'combined_data.csv' without duplicates.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data combined, sorted by 'prompt_id' and 'essay_id', and saved to 'combined_data.csv' without duplicates.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Base directory containing the subdirectories\n",
    "base_dir = ''\n",
    "combined_data = []\n",
    "\n",
    "# Loop through each numbered folder (1 to 8)\n",
    "for i in range(1, 9):\n",
    "    folder_path = os.path.join(base_dir, str(i))\n",
    "    \n",
    "    # List of file names to read from each subdirectory\n",
    "    file_names = ['train.pk', 'dev.pk', 'test.pk']\n",
    "    \n",
    "    # Load and append data from each file in the folder\n",
    "    for file_name in file_names:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Check if the file exists to avoid errors\n",
    "        if os.path.isfile(file_path):\n",
    "            with open(file_path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                \n",
    "                # Assuming each loaded file contains a list of dictionaries\n",
    "                combined_data.extend(data)\n",
    "\n",
    "# Convert to DataFrame, remove duplicates\n",
    "df = pd.DataFrame(combined_data)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Sort by 'prompt_id' and then by 'essay_id'\n",
    "df.sort_values(by=['prompt_id', 'essay_id'], inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('combined_data.csv', index=False)\n",
    "print(\"Data combined, sorted by 'prompt_id' and 'essay_id', and saved to 'combined_data.csv' without duplicates.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data combined, sorted by 'prompt_id' and 'essay_id', reordered, and saved to 'combined_data.csv' without duplicates.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Base directory containing the subdirectories\n",
    "base_dir = ''\n",
    "combined_data = []\n",
    "\n",
    "# Loop through each numbered folder (1 to 8)\n",
    "for i in range(1, 9):\n",
    "    folder_path = os.path.join(base_dir, str(i))\n",
    "    \n",
    "    # List of file names to read from each subdirectory\n",
    "    file_names = ['train.pk', 'dev.pk', 'test.pk']\n",
    "    \n",
    "    # Load and append data from each file in the folder\n",
    "    for file_name in file_names:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Check if the file exists to avoid errors\n",
    "        if os.path.isfile(file_path):\n",
    "            with open(file_path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                \n",
    "                # Assuming each loaded file contains a list of dictionaries\n",
    "                combined_data.extend(data)\n",
    "\n",
    "# Convert to DataFrame, remove duplicates\n",
    "df = pd.DataFrame(combined_data)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Sort by 'prompt_id' and then by 'essay_id'\n",
    "df.sort_values(by=['prompt_id', 'essay_id'], inplace=True)\n",
    "\n",
    "# Define the new column order\n",
    "new_order = ['essay_id', 'prompt_id', 'content_text'] + [col for col in df.columns if col not in ['essay_id', 'prompt_id', 'content_text']]\n",
    "\n",
    "# Reorder the DataFrame\n",
    "df = df[new_order]\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('combined_data.csv', index=False)\n",
    "print(\"Data combined, sorted by 'prompt_id' and 'essay_id', reordered, and saved to 'combined_data.csv' without duplicates.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data combined, sorted by 'prompt_id' and 'essay_id', reordered, and saved to 'combined_data.csv' without duplicates.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Base directory containing the subdirectories\n",
    "base_dir = ''\n",
    "combined_data = []\n",
    "\n",
    "# Loop through each numbered folder (1 to 8)\n",
    "for i in range(1, 9):\n",
    "    folder_path = os.path.join(base_dir, str(i))\n",
    "    \n",
    "    # List of file names to read from each subdirectory\n",
    "    file_names = ['train.pk', 'dev.pk', 'test.pk']\n",
    "    \n",
    "    # Load and append data from each file in the folder\n",
    "    for file_name in file_names:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Check if the file exists to avoid errors\n",
    "        if os.path.isfile(file_path):\n",
    "            with open(file_path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                \n",
    "                # Assuming each loaded file contains a list of dictionaries\n",
    "                combined_data.extend(data)\n",
    "\n",
    "# Convert to DataFrame, remove duplicates\n",
    "df = pd.DataFrame(combined_data)\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Convert 'essay_id' to integer for proper sorting\n",
    "df['essay_id'] = df['essay_id'].astype(int)\n",
    "\n",
    "# Sort by 'prompt_id' and then by 'essay_id'\n",
    "df.sort_values(by=['prompt_id', 'essay_id'], inplace=True)\n",
    "\n",
    "# Define the new column order\n",
    "new_order = ['essay_id', 'prompt_id', 'content_text'] + [col for col in df.columns if col not in ['essay_id', 'prompt_id', 'content_text']]\n",
    "\n",
    "# Reorder the DataFrame\n",
    "df = df[new_order]\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('combined_data.csv', index=False)\n",
    "print(\"Data combined, sorted by 'prompt_id' and 'essay_id', reordered, and saved to 'combined_data.csv' without duplicates.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "essay_id                0\n",
      "prompt_id               0\n",
      "content_text            0\n",
      "score                   0\n",
      "content                 1\n",
      "prompt_adherence     5874\n",
      "language             5874\n",
      "narrativity          5874\n",
      "organization         7103\n",
      "word_choice          8672\n",
      "sentence_fluency     8672\n",
      "conventions          7103\n",
      "style               11408\n",
      "voice               12254\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing essay_ids in combined_data.csv \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the combined data\n",
    "combined_data = pd.read_csv('combined_data.csv')\n",
    "\n",
    "# Check for missing values\n",
    "print(combined_data.isnull().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12977, 14)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_data = pd.read_csv('..\\\\..\\\\data\\\\LDA\\\\hand_crafted_final_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>highest_topic</th>\n",
       "      <th>mean_word</th>\n",
       "      <th>word_var</th>\n",
       "      <th>mean_sent</th>\n",
       "      <th>sent_var</th>\n",
       "      <th>ess_char_len</th>\n",
       "      <th>word_count</th>\n",
       "      <th>prep_comma</th>\n",
       "      <th>...</th>\n",
       "      <th>WDT</th>\n",
       "      <th>DT</th>\n",
       "      <th>CD</th>\n",
       "      <th>NN</th>\n",
       "      <th>TO</th>\n",
       "      <th>JJ</th>\n",
       "      <th>VBP</th>\n",
       "      <th>RP</th>\n",
       "      <th>NNS</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8894</td>\n",
       "      <td>4.400593</td>\n",
       "      <td>5.842492</td>\n",
       "      <td>21.062500</td>\n",
       "      <td>171.308594</td>\n",
       "      <td>1483</td>\n",
       "      <td>337</td>\n",
       "      <td>71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144330</td>\n",
       "      <td>0.025773</td>\n",
       "      <td>0.048969</td>\n",
       "      <td>0.030928</td>\n",
       "      <td>0.007732</td>\n",
       "      <td>0.043814</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8669</td>\n",
       "      <td>4.353222</td>\n",
       "      <td>5.469506</td>\n",
       "      <td>20.950000</td>\n",
       "      <td>142.247500</td>\n",
       "      <td>1824</td>\n",
       "      <td>419</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>0.075107</td>\n",
       "      <td>0.008584</td>\n",
       "      <td>0.122318</td>\n",
       "      <td>0.017167</td>\n",
       "      <td>0.042918</td>\n",
       "      <td>0.036481</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>0.087983</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9583</td>\n",
       "      <td>4.405018</td>\n",
       "      <td>5.545638</td>\n",
       "      <td>19.928571</td>\n",
       "      <td>184.637755</td>\n",
       "      <td>1229</td>\n",
       "      <td>279</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.006349</td>\n",
       "      <td>0.123810</td>\n",
       "      <td>0.025397</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8561</td>\n",
       "      <td>4.868321</td>\n",
       "      <td>6.415867</td>\n",
       "      <td>19.407407</td>\n",
       "      <td>135.722908</td>\n",
       "      <td>2551</td>\n",
       "      <td>524</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003247</td>\n",
       "      <td>0.069805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126623</td>\n",
       "      <td>0.024351</td>\n",
       "      <td>0.066558</td>\n",
       "      <td>0.040584</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.086039</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9266</td>\n",
       "      <td>4.408602</td>\n",
       "      <td>5.450249</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>43.516667</td>\n",
       "      <td>2050</td>\n",
       "      <td>465</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005780</td>\n",
       "      <td>0.104046</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.131021</td>\n",
       "      <td>0.040462</td>\n",
       "      <td>0.042389</td>\n",
       "      <td>0.036609</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>0.078998</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  prompt_id  highest_topic  mean_word  word_var  mean_sent  \\\n",
       "0        1          1         0.8894   4.400593  5.842492  21.062500   \n",
       "1        2          1         0.8669   4.353222  5.469506  20.950000   \n",
       "2        3          1         0.9583   4.405018  5.545638  19.928571   \n",
       "3        4          1         0.8561   4.868321  6.415867  19.407407   \n",
       "4        5          1         0.9266   4.408602  5.450249  15.500000   \n",
       "\n",
       "     sent_var  ess_char_len  word_count  prep_comma  ...       WDT        DT  \\\n",
       "0  171.308594          1483         337          71  ...  0.000000  0.051546   \n",
       "1  142.247500          1824         419          70  ...  0.002146  0.075107   \n",
       "2  184.637755          1229         279          41  ...  0.000000  0.085714   \n",
       "3  135.722908          2551         524          77  ...  0.003247  0.069805   \n",
       "4   43.516667          2050         465          56  ...  0.005780  0.104046   \n",
       "\n",
       "         CD        NN        TO        JJ       VBP        RP       NNS  score  \n",
       "0  0.000000  0.144330  0.025773  0.048969  0.030928  0.007732  0.043814    8.0  \n",
       "1  0.008584  0.122318  0.017167  0.042918  0.036481  0.004292  0.087983    9.0  \n",
       "2  0.006349  0.123810  0.025397  0.047619  0.076190  0.009524  0.111111    7.0  \n",
       "3  0.000000  0.126623  0.024351  0.066558  0.040584  0.001623  0.086039   10.0  \n",
       "4  0.009634  0.131021  0.040462  0.042389  0.036609  0.001927  0.078998    8.0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12978, 55)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12565    4365\n",
       "Name: item_id, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# find out which two essay ids are missing in combined_data.csv from lda_data\n",
    "missing_ids = lda_data[~lda_data['item_id'].isin(combined_data['essay_id'])]['item_id']\n",
    "\n",
    "missing_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_ids = [4355,4365]\n",
    "\n",
    "# Load the training_set_rel3.tsv file and prompt2.csv file and fill the values for the missing essay_ids\n",
    "# contains essay details\n",
    "training_set = pd.read_csv('..\\\\..\\\\data\\\\training_set_rel3.tsv', sep='\\t', encoding='ISO-8859-1')\n",
    "# contains scores\n",
    "prompt2 = pd.read_csv('..\\\\..\\\\Feedback\\\\Prompt-2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['essay_id', 'essay_set', 'essay', 'rater1_domain1', 'rater2_domain1',\n",
       "       'rater3_domain1', 'domain1_score', 'rater1_domain2', 'rater2_domain2',\n",
       "       'domain2_score', 'rater1_trait1', 'rater1_trait2', 'rater1_trait3',\n",
       "       'rater1_trait4', 'rater1_trait5', 'rater1_trait6', 'rater2_trait1',\n",
       "       'rater2_trait2', 'rater2_trait3', 'rater2_trait4', 'rater2_trait5',\n",
       "       'rater2_trait6', 'rater3_trait1', 'rater3_trait2', 'rater3_trait3',\n",
       "       'rater3_trait4', 'rater3_trait5', 'rater3_trait6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "essay_id          0.000000\n",
       "essay_set         0.000000\n",
       "essay             0.000000\n",
       "rater1_domain1    0.000000\n",
       "rater2_domain1    0.000000\n",
       "rater3_domain1    0.990136\n",
       "domain1_score     0.000000\n",
       "rater1_domain2    0.861282\n",
       "rater2_domain2    0.861282\n",
       "domain2_score     0.861282\n",
       "rater1_trait1     0.823366\n",
       "rater1_trait2     0.823366\n",
       "rater1_trait3     0.823366\n",
       "rater1_trait4     0.823366\n",
       "rater1_trait5     0.944282\n",
       "rater1_trait6     0.944282\n",
       "rater2_trait1     0.823366\n",
       "rater2_trait2     0.823366\n",
       "rater2_trait3     0.823366\n",
       "rater2_trait4     0.823366\n",
       "rater2_trait5     0.944282\n",
       "rater2_trait6     0.944282\n",
       "rater3_trait1     0.990136\n",
       "rater3_trait2     0.990136\n",
       "rater3_trait3     0.990136\n",
       "rater3_trait4     0.990136\n",
       "rater3_trait5     0.990136\n",
       "rater3_trait6     0.990136\n",
       "dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage ofmissing data in training_set\n",
    "training_set.isnull().sum()/training_set.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EssayID', 'Content', 'Organization', 'Word Choice', 'Sentence Fluency',\n",
       "       'Conventions'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['essay_id', 'prompt_id', 'content_text', 'score', 'content',\n",
       "       'prompt_adherence', 'language', 'narrativity', 'organization',\n",
       "       'word_choice', 'sentence_fluency', 'conventions', 'style', 'voice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>highest_topic</th>\n",
       "      <th>mean_word</th>\n",
       "      <th>word_var</th>\n",
       "      <th>mean_sent</th>\n",
       "      <th>sent_var</th>\n",
       "      <th>ess_char_len</th>\n",
       "      <th>word_count</th>\n",
       "      <th>prep_comma</th>\n",
       "      <th>...</th>\n",
       "      <th>WDT</th>\n",
       "      <th>DT</th>\n",
       "      <th>CD</th>\n",
       "      <th>NN</th>\n",
       "      <th>TO</th>\n",
       "      <th>JJ</th>\n",
       "      <th>VBP</th>\n",
       "      <th>RP</th>\n",
       "      <th>NNS</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12565</th>\n",
       "      <td>4365</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>4.224335</td>\n",
       "      <td>5.154997</td>\n",
       "      <td>18.785714</td>\n",
       "      <td>64.096939</td>\n",
       "      <td>2222</td>\n",
       "      <td>526</td>\n",
       "      <td>82</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011647</td>\n",
       "      <td>0.116473</td>\n",
       "      <td>0.003328</td>\n",
       "      <td>0.144759</td>\n",
       "      <td>0.024958</td>\n",
       "      <td>0.03827</td>\n",
       "      <td>0.028286</td>\n",
       "      <td>0.008319</td>\n",
       "      <td>0.073211</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_id  prompt_id  highest_topic  mean_word  word_var  mean_sent  \\\n",
       "12565     4365          2         0.9848   4.224335  5.154997  18.785714   \n",
       "\n",
       "        sent_var  ess_char_len  word_count  prep_comma  ...       WDT  \\\n",
       "12565  64.096939          2222         526          82  ...  0.011647   \n",
       "\n",
       "             DT        CD        NN        TO       JJ       VBP        RP  \\\n",
       "12565  0.116473  0.003328  0.144759  0.024958  0.03827  0.028286  0.008319   \n",
       "\n",
       "            NNS  score  \n",
       "12565  0.073211    4.0  \n",
       "\n",
       "[1 rows x 55 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find datapoint with item_id as 4365\n",
    "lda_data[lda_data['item_id'] == 4365]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3170</th>\n",
       "      <td>4365</td>\n",
       "      <td>2</td>\n",
       "      <td>Katherine stated that if everyone had the righ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id  essay_set                                              essay  \\\n",
       "3170      4365          2  Katherine stated that if everyone had the righ...   \n",
       "\n",
       "      rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "3170               4               4             NaN              4   \n",
       "\n",
       "      rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait3  \\\n",
       "3170             4.0             4.0            4.0  ...            NaN   \n",
       "\n",
       "      rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  \\\n",
       "3170            NaN            NaN            NaN            NaN   \n",
       "\n",
       "      rater3_trait2  rater3_trait3  rater3_trait4  rater3_trait5  \\\n",
       "3170            NaN            NaN            NaN            NaN   \n",
       "\n",
       "      rater3_trait6  \n",
       "3170            NaN  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[training_set['essay_id'] == 4365]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EssayID</th>\n",
       "      <th>Content</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Word Choice</th>\n",
       "      <th>Sentence Fluency</th>\n",
       "      <th>Conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>4365</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      EssayID  Content  Organization  Word Choice  Sentence Fluency  \\\n",
       "1378     4365        6             6            6                 6   \n",
       "\n",
       "      Conventions  \n",
       "1378            6  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt2[prompt2['EssayID'] == 4365]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   essay_id  prompt_id                                       content_text  \\\n",
      "0      4365          2  Katherine stated that if everyone had the righ...   \n",
      "\n",
      "   score  organization  word_choice  sentence_fluency  conventions style voice  \n",
      "0      4             6            6                 6            6              \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def fill_missing_essays(missing_ids, training_tsv_path, prompt_csv_path):\n",
    "    # Load the training_set_rel3.tsv file\n",
    "    training_set = pd.read_csv(training_tsv_path, sep='\\t', encoding='ISO-8859-1')\n",
    "\n",
    "    # Load the Prompt-2.csv file\n",
    "    prompt2 = pd.read_csv(prompt_csv_path)\n",
    "\n",
    "    # Filter training_set to include only the missing essay_ids\n",
    "    training_missing = training_set[training_set['essay_id'].isin(missing_ids)]\n",
    "\n",
    "    # Filter prompt2 to include only the missing essay_ids\n",
    "    prompt_missing = prompt2[prompt2['EssayID'].isin(missing_ids)]\n",
    "\n",
    "    # Combine the two filtered DataFrames to get the required information\n",
    "    combined_missing = pd.merge(training_missing, prompt_missing, left_on='essay_id', right_on='EssayID', how='inner')\n",
    "\n",
    "    # Select and rename the relevant columns to match the combined_data.csv structure\n",
    "    combined_missing = combined_missing.rename(columns={\n",
    "        'essay_id': 'essay_id',\n",
    "        'essay_set': 'prompt_id',  # Assuming essay_set corresponds to prompt_id\n",
    "        'essay': 'content_text',\n",
    "        'domain1_score' : 'score',\n",
    "        'Content':'content',\n",
    "        'Organization': 'organization',\n",
    "        'Word Choice' : 'word_choice',\n",
    "        'Sentence Fluency' : 'sentence_fluency',\n",
    "        'Conventions': 'conventions'\n",
    "    })\n",
    "\n",
    "    # Add placeholder columns for style and voice\n",
    "    combined_missing['style'] = ''  # or any default value\n",
    "    combined_missing['voice'] = ''  # or any default value\n",
    "\n",
    "    # Select only the columns needed for the final DataFrame\n",
    "    final_columns = [\n",
    "        'essay_id', 'prompt_id', 'content_text', 'score',\n",
    "        'organization', 'word_choice', 'sentence_fluency', 'conventions', 'style', 'voice'\n",
    "    ]\n",
    "\n",
    "    combined_missing = combined_missing[final_columns]\n",
    "\n",
    "    return combined_missing\n",
    "\n",
    "# Example usage\n",
    "missing_ids = [4365]\n",
    "training_tsv_path = '..\\\\..\\\\data\\\\training_set_rel3.tsv'\n",
    "prompt_csv_path = '..\\\\..\\\\Feedback\\\\Prompt-2.csv'\n",
    "\n",
    "# Fill in missing essay details\n",
    "missing_essays_df = fill_missing_essays(missing_ids, training_tsv_path, prompt_csv_path)\n",
    "\n",
    "# Display the DataFrame with filled values\n",
    "print(missing_essays_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_essays_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add missing_essay_df to combined_data.csv\n",
    "combined_data = pd.read_csv('combined_data.csv')\n",
    "\n",
    "# Append the missing_essays_df to the combined_data DataFrame\n",
    "combined_data = pd.concat([combined_data, missing_essays_df], ignore_index=True)\n",
    "\n",
    "# Sort by 'prompt_id' and then by 'essay_id'\n",
    "combined_data.sort_values(by=['prompt_id', 'essay_id'], inplace=True)\n",
    "\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "combined_data.to_csv('combined_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12978, 14)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12978, 55)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
